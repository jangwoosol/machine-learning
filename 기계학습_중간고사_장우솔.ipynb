{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "기계학습 중간고사 장우솔",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdL52C1rId_d"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt  # Para plotar graficos\n",
        "import numpy as np  # Array do Python\n",
        "import math\n",
        "from math  import sqrt, pi\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oGhgf_Zqiu"
      },
      "source": [
        "#train data 생성\n",
        "np.random.seed(100)\n",
        "data=[]\n",
        "data=pd.DataFrame(np.random.uniform(0,3,100))\n",
        "data['x2']=pd.DataFrame(np.random.uniform(2,4,100))\n",
        "data['x3']=pd.DataFrame(np.random.uniform(-2,2,100))\n",
        "data['trian']=pd.DataFrame(np.random.triangular(-2,0,2,100))\n",
        "data['x4']=1/3*data['x3']+2/3*data['trian']\n",
        "data.columns=['x1','x2','x3','dr','x4']\n",
        "train=data.drop('dr',axis=1)\n",
        "#y 만들기\n",
        "noise = np.random.normal(0, 0.5, size=100)\n",
        "train_y=-data['x1']+2*data['x2']-0.5*((1/(2**(1/2))*data['x3'])+(1/(2**(1/2))*data['x4'])-(1/(2**(1/2))))**2+6\n",
        "train_y_noise=train_y+noise\n",
        "train_y_noise=pd.DataFrame(train_y_noise, columns=['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgItQwb4nPPi"
      },
      "source": [
        "#test data 생성\n",
        "np.random.seed(1)\n",
        "data=[]\n",
        "data=pd.DataFrame(np.random.uniform(0,3,100))\n",
        "data['x2']=pd.DataFrame(np.random.uniform(2,4,100))\n",
        "data['x3']=pd.DataFrame(np.random.uniform(-2,2,100))\n",
        "data['trian']=pd.DataFrame(np.random.triangular(-2,0,2,100))\n",
        "data['x4']=1/3*data['x3']+2/3*data['trian']\n",
        "data.columns=['x1','x2','x3','dr','x4']\n",
        "test=data.drop('dr',axis=1)\n",
        "#y 만들기\n",
        "noise = np.random.normal(0, 0.5, size=100)\n",
        "test_y=-data['x1']+2*data['x2']-0.5*((1/(2**(1/2))*data['x3'])+(1/(2**(1/2))*data['x4'])-(1/(2**(1/2))))**2+6\n",
        "test_y_noise=test_y+noise\n",
        "test_y_noise=pd.DataFrame(test_y_noise, columns=['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChhkdXJoBEU"
      },
      "source": [
        "#분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(train,train_y, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBBNetgph_A"
      },
      "source": [
        "# Defining the Mexican Hat Wavelet Function\n",
        "def mexican(z):\n",
        "    return tf.multiply(tf.multiply(tf.multiply(2/sqrt(3),tf.pow(pi,-0.25)),tf.subtract(tf.constant(1.0), tf.pow(z,2))), tf.exp(tf.multiply(tf.constant(-0.5), tf.pow(z,2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeBz5d8mftFd"
      },
      "source": [
        "#임의로 케라스 모델 생성\n",
        "tf.random.set_seed(77)\n",
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3,input_shape=[4]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nmm-RZzwk7A",
        "outputId": "3b785b2f-a9d2-4c3c-ed97-04188a38738f"
      },
      "source": [
        "#클래스의 객체를 생성\n",
        "tf.random.set_seed(77)\n",
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "keras_reg.fit(x_train, y_train, epochs=100,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 91.3961 - val_loss: 39.9800\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 33.0390 - val_loss: 11.0239\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 8.5233 - val_loss: 4.4965\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 4.3329 - val_loss: 3.5015\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.7461 - val_loss: 3.3533\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.5270 - val_loss: 2.9903\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.2450 - val_loss: 2.9564\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.0134 - val_loss: 2.6868\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.7619 - val_loss: 2.5942\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.5808 - val_loss: 2.2609\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.4312 - val_loss: 2.3065\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 2.2418 - val_loss: 2.2188\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.1099 - val_loss: 2.1308\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.9893 - val_loss: 2.1286\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.8845 - val_loss: 2.1456\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.7880 - val_loss: 1.8323\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.6936 - val_loss: 1.7018\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.6406 - val_loss: 1.7139\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.5849 - val_loss: 1.5993\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.5460 - val_loss: 1.6037\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.3858 - val_loss: 1.5899\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.3108 - val_loss: 1.5707\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.2608 - val_loss: 1.4968\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.2211 - val_loss: 1.5130\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.1831 - val_loss: 1.4775\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.1479 - val_loss: 1.4229\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.1109 - val_loss: 1.4239\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.0693 - val_loss: 1.4616\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.0383 - val_loss: 1.4270\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.0123 - val_loss: 1.4688\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.9946 - val_loss: 1.3508\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.9930 - val_loss: 1.3469\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9742 - val_loss: 1.3295\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9678 - val_loss: 1.3552\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9224 - val_loss: 1.3059\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.9108 - val_loss: 1.3305\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8916 - val_loss: 1.3207\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8906 - val_loss: 1.2973\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8835 - val_loss: 1.3207\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8612 - val_loss: 1.3865\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8599 - val_loss: 1.2812\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8486 - val_loss: 1.2979\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.8374 - val_loss: 1.2568\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8338 - val_loss: 1.3250\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8244 - val_loss: 1.3072\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8153 - val_loss: 1.2770\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.8141 - val_loss: 1.2734\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8042 - val_loss: 1.2753\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8041 - val_loss: 1.2235\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8205 - val_loss: 1.2277\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7972 - val_loss: 1.1970\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8119 - val_loss: 1.1946\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7904 - val_loss: 1.2408\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7785 - val_loss: 1.2067\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8000 - val_loss: 1.2356\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.7791 - val_loss: 1.2750\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.7778 - val_loss: 1.2485\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.7693 - val_loss: 1.2017\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7637 - val_loss: 1.2041\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.7740 - val_loss: 1.2013\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 1.2013\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.7659 - val_loss: 1.2033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05e2db8bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSiMWDJxn7m",
        "outputId": "d9569b34-f3cd-4e8d-ac60-5cb84831dd52"
      },
      "source": [
        "#RandomizedsearchCV를 이용하여 하이퍼파라미터 공간을 탐색한다.\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "tf.random.set_seed(77)\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(2, 15).tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, scoring='neg_mean_absolute_error', n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(x_train, y_train, epochs=100,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006 ....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 105.0807 - val_loss: 88.9460\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 101.1041 - val_loss: 85.7515\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 97.0712 - val_loss: 82.5062\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 92.9404 - val_loss: 79.1705\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 88.6760 - val_loss: 75.5723\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 84.0515 - val_loss: 71.8969\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 79.3527 - val_loss: 68.3263\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 74.7304 - val_loss: 64.5170\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 70.0116 - val_loss: 60.5746\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 65.0529 - val_loss: 56.0863\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 59.5189 - val_loss: 51.2472\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 53.5306 - val_loss: 45.8547\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 46.9616 - val_loss: 40.0589\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 40.0183 - val_loss: 33.9511\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 32.8818 - val_loss: 27.9270\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 26.0671 - val_loss: 22.3544\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 19.8780 - val_loss: 17.2742\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 14.5140 - val_loss: 12.9880\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.2979 - val_loss: 9.7743\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.3293 - val_loss: 7.3724\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.3996 - val_loss: 5.9916\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 4.4557 - val_loss: 5.2287\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.9084 - val_loss: 4.6431\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.5610 - val_loss: 4.2302\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.3748 - val_loss: 4.0044\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 3.2746 - val_loss: 3.6938\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.1506 - val_loss: 3.5741\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.1066 - val_loss: 3.4692\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.0610 - val_loss: 3.4232\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.0329 - val_loss: 3.4095\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.9936 - val_loss: 3.3586\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9621 - val_loss: 3.3113\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.9639 - val_loss: 3.3686\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.9052 - val_loss: 3.2794\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.8679 - val_loss: 3.2310\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.8330 - val_loss: 3.1926\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.8502 - val_loss: 3.0700\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.8198 - val_loss: 3.1667\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.7439 - val_loss: 3.1095\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.7423 - val_loss: 3.0006\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.6836 - val_loss: 2.9799\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.6730 - val_loss: 3.0411\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.6219 - val_loss: 2.9910\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.5940 - val_loss: 2.9498\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.5800 - val_loss: 2.8783\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.5503 - val_loss: 2.9189\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.5156 - val_loss: 2.9275\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.5041 - val_loss: 2.9508\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.4634 - val_loss: 2.9109\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.4337 - val_loss: 2.8721\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.4164 - val_loss: 2.8734\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.3805 - val_loss: 2.8058\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.3549 - val_loss: 2.7487\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.3443 - val_loss: 2.6735\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.3110 - val_loss: 2.6408\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.2993 - val_loss: 2.5944\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.2817 - val_loss: 2.6585\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.2356 - val_loss: 2.6560\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.2153 - val_loss: 2.6536\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1895 - val_loss: 2.6114\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.1670 - val_loss: 2.5709\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.1451 - val_loss: 2.5678\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.1274 - val_loss: 2.5079\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.0996 - val_loss: 2.4825\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.0785 - val_loss: 2.4596\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0659 - val_loss: 2.4921\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0557 - val_loss: 2.4151\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.0399 - val_loss: 2.4724\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0112 - val_loss: 2.4872\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9804 - val_loss: 2.4562\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9615 - val_loss: 2.4370\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9391 - val_loss: 2.3987\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9209 - val_loss: 2.3543\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.9023 - val_loss: 2.3186\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8893 - val_loss: 2.2798\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8694 - val_loss: 2.2563\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.8577 - val_loss: 2.2903\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.8333 - val_loss: 2.2915\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.8257 - val_loss: 2.2280\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8014 - val_loss: 2.2000\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7817 - val_loss: 2.2069\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.8026 - val_loss: 2.1352\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.7576 - val_loss: 2.1688\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7344 - val_loss: 2.1561\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7223 - val_loss: 2.1692\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.7055 - val_loss: 2.1636\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.6911 - val_loss: 2.1323\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7147 - val_loss: 2.1949\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.6661 - val_loss: 2.1529\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.6839 - val_loss: 2.0601\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.6379 - val_loss: 2.0831\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.6253 - val_loss: 2.0428\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.6060 - val_loss: 2.0295\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.5956 - val_loss: 2.0052\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5823 - val_loss: 1.9891\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5764 - val_loss: 2.0271\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.5507 - val_loss: 2.0067\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5395 - val_loss: 2.0113\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.5273 - val_loss: 2.0106\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.5165 - val_loss: 1.9679\n",
            "[CV]  n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006, total=   3.7s\n",
            "[CV] n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006 ....\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2115 - val_loss: 2.0496\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2103 - val_loss: 2.0987\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.1733 - val_loss: 2.0918\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1749 - val_loss: 2.0022\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.1271 - val_loss: 1.9898\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.1053 - val_loss: 1.9828\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.0966 - val_loss: 1.9408\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0700 - val_loss: 1.9226\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.0758 - val_loss: 1.8793\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.0306 - val_loss: 1.9063\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0028 - val_loss: 1.9186\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.9809 - val_loss: 1.9078\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.9702 - val_loss: 1.9305\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.9599 - val_loss: 1.8662\n",
            "[CV]  n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006, total=   3.5s\n",
            "[CV] n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 104.9607 - val_loss: 90.8628\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 98.8232 - val_loss: 85.6582\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 92.9548 - val_loss: 80.5406\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 87.1033 - val_loss: 75.2694\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 81.0424 - val_loss: 69.4922\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 74.4659 - val_loss: 63.3922\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 67.4715 - val_loss: 56.8899\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 60.0739 - val_loss: 49.9274\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 52.1586 - val_loss: 42.6399\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 43.9694 - val_loss: 35.2745\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 35.6930 - val_loss: 28.0782\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 27.6596 - val_loss: 21.3723\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 20.3351 - val_loss: 15.7060\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 14.2563 - val_loss: 11.3802\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 9.7189 - val_loss: 8.3038\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 6.5581 - val_loss: 6.2298\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.5252 - val_loss: 5.0545\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4248 - val_loss: 4.4192\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.8236 - val_loss: 4.0199\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.4664 - val_loss: 3.7532\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.2527 - val_loss: 3.6188\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.1437 - val_loss: 3.5121\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.0624 - val_loss: 3.4293\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.9985 - val_loss: 3.3593\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9583 - val_loss: 3.2749\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8814 - val_loss: 3.2193\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.8345 - val_loss: 3.1739\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7942 - val_loss: 3.1051\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.7367 - val_loss: 3.0506\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.6945 - val_loss: 2.9979\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.6546 - val_loss: 2.9469\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.6189 - val_loss: 2.9184\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.5899 - val_loss: 2.8897\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5366 - val_loss: 2.8446\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.5339 - val_loss: 2.8273\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.4801 - val_loss: 2.7825\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4382 - val_loss: 2.7325\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4017 - val_loss: 2.6762\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.3631 - val_loss: 2.6371\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.3353 - val_loss: 2.6042\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.3072 - val_loss: 2.5722\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.2950 - val_loss: 2.5567\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.2554 - val_loss: 2.5096\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.2286 - val_loss: 2.4819\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.2054 - val_loss: 2.4584\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1870 - val_loss: 2.4359\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1587 - val_loss: 2.3974\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1365 - val_loss: 2.3719\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.1227 - val_loss: 2.3307\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0948 - val_loss: 2.3033\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0737 - val_loss: 2.2842\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.0683 - val_loss: 2.2791\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0380 - val_loss: 2.2547\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.0200 - val_loss: 2.2303\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0056 - val_loss: 2.2120\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9863 - val_loss: 2.1889\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9717 - val_loss: 2.1637\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9564 - val_loss: 2.1457\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9431 - val_loss: 2.1293\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.9292 - val_loss: 2.1059\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.9172 - val_loss: 2.0812\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9034 - val_loss: 2.0623\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8930 - val_loss: 2.0426\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8793 - val_loss: 2.0293\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8705 - val_loss: 2.0095\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8577 - val_loss: 1.9970\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8463 - val_loss: 1.9847\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8353 - val_loss: 1.9670\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8242 - val_loss: 1.9506\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8186 - val_loss: 1.9475\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8136 - val_loss: 1.9173\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7932 - val_loss: 1.9081\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7842 - val_loss: 1.8917\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7744 - val_loss: 1.8799\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7736 - val_loss: 1.8837\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7588 - val_loss: 1.8726\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7533 - val_loss: 1.8548\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7471 - val_loss: 1.8488\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7409 - val_loss: 1.8460\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7386 - val_loss: 1.8437\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7356 - val_loss: 1.8400\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7247 - val_loss: 1.8241\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.7169 - val_loss: 1.8048\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7122 - val_loss: 1.7984\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7060 - val_loss: 1.7899\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7084 - val_loss: 1.7624\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7033 - val_loss: 1.7451\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6905 - val_loss: 1.7396\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6871 - val_loss: 1.7465\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6833 - val_loss: 1.7300\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6803 - val_loss: 1.7170\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6726 - val_loss: 1.7208\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.6652 - val_loss: 1.7148\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6617 - val_loss: 1.7058\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6570 - val_loss: 1.7009\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6560 - val_loss: 1.6868\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6500 - val_loss: 1.6869\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6468 - val_loss: 1.6807\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6432 - val_loss: 1.6780\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6434 - val_loss: 1.6631\n",
            "[CV]  n_neurons=9, n_hidden=3, learning_rate=0.0004051580153583006, total=   3.6s\n",
            "[CV] n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 54.2713 - val_loss: 3.5960\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 4.7809 - val_loss: 2.8508\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.1799 - val_loss: 2.4961\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.5641 - val_loss: 2.6057\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.2386 - val_loss: 2.7396\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.3542 - val_loss: 3.6555\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.4031 - val_loss: 2.3965\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.8435 - val_loss: 2.9595\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.8526 - val_loss: 1.9255\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.8657 - val_loss: 5.0597\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 3.3167 - val_loss: 2.0447\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.3885 - val_loss: 2.0686\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.1624 - val_loss: 1.4982\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0803 - val_loss: 1.5128\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3245 - val_loss: 1.5237\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1287 - val_loss: 1.4190\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0235 - val_loss: 1.4981\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0169 - val_loss: 1.5236\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9729 - val_loss: 1.6241\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8923 - val_loss: 1.4519\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9373 - val_loss: 1.4644\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1416 - val_loss: 2.4817\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9540 - val_loss: 2.2705\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.6898 - val_loss: 2.0401\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1474 - val_loss: 1.3919\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8748 - val_loss: 1.5152\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9619 - val_loss: 1.3946\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8314 - val_loss: 1.3300\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8109 - val_loss: 1.3533\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9239 - val_loss: 2.0793\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.3658 - val_loss: 1.5475\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.9256 - val_loss: 1.3893\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0023 - val_loss: 2.1854\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.2691 - val_loss: 1.3405\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7835 - val_loss: 1.2974\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7710 - val_loss: 1.3115\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7676 - val_loss: 1.2849\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7708 - val_loss: 1.5824\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.1469 - val_loss: 1.9492\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0697 - val_loss: 1.2889\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7569 - val_loss: 1.3753\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8319 - val_loss: 1.4994\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8583 - val_loss: 1.3375\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7386 - val_loss: 1.2496\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.7231 - val_loss: 1.3426\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8558 - val_loss: 1.5831\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0573 - val_loss: 1.6736\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.4624 - val_loss: 2.7062\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5573 - val_loss: 1.2390\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7063 - val_loss: 1.2989\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7846 - val_loss: 1.3743\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8814 - val_loss: 1.5594\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8282 - val_loss: 1.2766\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6780 - val_loss: 1.2566\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6748 - val_loss: 1.2559\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6727 - val_loss: 1.2453\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6703 - val_loss: 1.3093\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7577 - val_loss: 1.3558\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7045 - val_loss: 1.2302\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6566 - val_loss: 1.2327\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6585 - val_loss: 1.2242\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6739 - val_loss: 1.2961\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7098 - val_loss: 1.2453\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6423 - val_loss: 1.2100\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6934 - val_loss: 1.1858\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6497 - val_loss: 1.4432\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7069 - val_loss: 1.2141\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6519 - val_loss: 1.6721\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0184 - val_loss: 1.2639\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6472 - val_loss: 1.1651\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6576 - val_loss: 1.1534\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6201 - val_loss: 1.1735\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7314 - val_loss: 1.3933\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8036 - val_loss: 1.1487\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6128 - val_loss: 1.1336\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7376 - val_loss: 1.1639\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7070 - val_loss: 1.1081\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6010 - val_loss: 1.1073\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6093 - val_loss: 1.1949\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7015 - val_loss: 1.1412\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6176 - val_loss: 1.1128\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6704 - val_loss: 1.4153\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7242 - val_loss: 1.1126\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5841 - val_loss: 1.0914\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5779 - val_loss: 1.0923\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5702 - val_loss: 1.0824\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5899 - val_loss: 1.0687\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7746 - val_loss: 2.4822\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.6752 - val_loss: 1.1661\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6681 - val_loss: 1.0993\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6575 - val_loss: 1.2553\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6418 - val_loss: 1.0800\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5540 - val_loss: 1.1350\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5687 - val_loss: 1.0734\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6015 - val_loss: 1.1465\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6030 - val_loss: 1.9661\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3219 - val_loss: 1.1781\n",
            "[CV]  n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584, total=   3.5s\n",
            "[CV] n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 112.9896 - val_loss: 43.5039\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 34.5098 - val_loss: 3.1117\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.6686 - val_loss: 2.7835\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.2119 - val_loss: 4.3926\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.1702 - val_loss: 2.1457\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.1123 - val_loss: 2.5473\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.8435 - val_loss: 1.6617\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0002 - val_loss: 2.0197\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.2027 - val_loss: 1.4116\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2024 - val_loss: 2.2212\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.5309 - val_loss: 1.5387\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.1121 - val_loss: 1.5439\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9592 - val_loss: 1.1735\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8963 - val_loss: 1.1372\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8271 - val_loss: 1.1659\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7907 - val_loss: 1.1242\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7697 - val_loss: 1.0863\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7794 - val_loss: 1.4511\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9313 - val_loss: 1.1870\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7677 - val_loss: 1.3284\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0043 - val_loss: 1.0556\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7096 - val_loss: 1.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7941 - val_loss: 1.2634\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8346 - val_loss: 1.1951\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6896 - val_loss: 1.0091\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8293 - val_loss: 1.0795\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8356 - val_loss: 0.9887\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6616 - val_loss: 1.1501\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8343 - val_loss: 1.4142\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0582 - val_loss: 1.4764\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8928 - val_loss: 1.0323\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6910 - val_loss: 1.2092\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.9046 - val_loss: 1.5258\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8247 - val_loss: 0.9388\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6284 - val_loss: 0.9432\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6004 - val_loss: 0.9853\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6165 - val_loss: 0.9612\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7005 - val_loss: 1.4040\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8107 - val_loss: 0.8996\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6145 - val_loss: 0.9717\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8355 - val_loss: 0.9481\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6720 - val_loss: 0.8922\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5720 - val_loss: 0.8928\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5640 - val_loss: 0.8822\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5603 - val_loss: 1.0239\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7062 - val_loss: 1.1091\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6497 - val_loss: 0.8846\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5479 - val_loss: 0.9097\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5547 - val_loss: 0.9836\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6592 - val_loss: 0.8592\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5293 - val_loss: 0.8720\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5728 - val_loss: 1.0396\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5450 - val_loss: 0.9121\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6137 - val_loss: 0.8384\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5579 - val_loss: 0.8785\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5696 - val_loss: 0.8307\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5063 - val_loss: 0.8285\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5132 - val_loss: 0.8400\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5064 - val_loss: 0.8891\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5155 - val_loss: 0.8123\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5066 - val_loss: 0.9734\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5826 - val_loss: 0.8414\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4850 - val_loss: 0.8145\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5664 - val_loss: 0.8987\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8001 - val_loss: 0.9541\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6455 - val_loss: 0.7879\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5589 - val_loss: 0.8791\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5877 - val_loss: 0.7761\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4721 - val_loss: 0.7670\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4616 - val_loss: 0.8328\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4589 - val_loss: 0.8479\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5182 - val_loss: 0.7537\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4681 - val_loss: 0.8084\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4491 - val_loss: 0.7714\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5854 - val_loss: 0.7932\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6442 - val_loss: 0.8532\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6605 - val_loss: 0.7929\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5253 - val_loss: 0.7233\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4597 - val_loss: 0.7184\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4272 - val_loss: 0.8031\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6453 - val_loss: 1.3053\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7643 - val_loss: 0.7277\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4194 - val_loss: 0.7468\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4161 - val_loss: 0.7070\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4223 - val_loss: 0.6913\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4625 - val_loss: 0.8151\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6672 - val_loss: 0.7553\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4180 - val_loss: 0.8652\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5418 - val_loss: 0.7425\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4011 - val_loss: 0.7168\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4326 - val_loss: 0.6689\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3884 - val_loss: 0.6665\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3905 - val_loss: 0.6612\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3905 - val_loss: 0.6658\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4845 - val_loss: 0.7543\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4344 - val_loss: 0.6730\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3951 - val_loss: 0.6650\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4113 - val_loss: 0.7111\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4588 - val_loss: 0.7476\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4288 - val_loss: 0.6403\n",
            "[CV]  n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584, total=   3.7s\n",
            "[CV] n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 81.9723 - val_loss: 21.2076\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 15.3186 - val_loss: 5.6115\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 4.2227 - val_loss: 7.1088\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 4.4597 - val_loss: 4.0330\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.1711 - val_loss: 3.3920\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.9982 - val_loss: 3.0396\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2319 - val_loss: 3.2365\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 3.3143 - val_loss: 3.0485\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.3264 - val_loss: 2.2285\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5014 - val_loss: 2.2305\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2142 - val_loss: 2.0958\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9359 - val_loss: 2.1502\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8888 - val_loss: 1.9006\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9985 - val_loss: 1.8410\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.8352 - val_loss: 2.0292\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8650 - val_loss: 1.9658\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9255 - val_loss: 2.3151\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1184 - val_loss: 2.1083\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7816 - val_loss: 1.6073\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9008 - val_loss: 1.6959\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7607 - val_loss: 1.8126\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6854 - val_loss: 1.5301\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6368 - val_loss: 1.6629\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6264 - val_loss: 1.4808\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7334 - val_loss: 1.4366\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6756 - val_loss: 1.4288\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6008 - val_loss: 1.4882\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5864 - val_loss: 1.3972\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5870 - val_loss: 1.3924\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5678 - val_loss: 1.4366\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5614 - val_loss: 1.3921\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6076 - val_loss: 1.8111\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9334 - val_loss: 1.9765\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9495 - val_loss: 1.5683\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8483 - val_loss: 2.0477\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0144 - val_loss: 1.5168\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7296 - val_loss: 1.6477\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5977 - val_loss: 1.2356\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5351 - val_loss: 1.2325\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5435 - val_loss: 1.2223\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5563 - val_loss: 1.2232\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5234 - val_loss: 1.5582\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6604 - val_loss: 1.3633\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5625 - val_loss: 1.3538\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5668 - val_loss: 1.3487\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6060 - val_loss: 1.4740\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6028 - val_loss: 1.2595\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4755 - val_loss: 1.1619\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4981 - val_loss: 1.1511\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4966 - val_loss: 1.1425\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4935 - val_loss: 1.1368\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4665 - val_loss: 1.3445\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5740 - val_loss: 1.2657\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5160 - val_loss: 1.2308\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4856 - val_loss: 1.1737\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4972 - val_loss: 1.3449\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4997 - val_loss: 1.1033\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4409 - val_loss: 1.1320\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4643 - val_loss: 1.2437\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4702 - val_loss: 1.0878\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4397 - val_loss: 1.0703\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4362 - val_loss: 1.0818\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4324 - val_loss: 1.0460\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4294 - val_loss: 1.1646\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4279 - val_loss: 1.0655\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5726 - val_loss: 1.0288\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5045 - val_loss: 1.0121\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4639 - val_loss: 1.0046\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4531 - val_loss: 0.9996\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4215 - val_loss: 1.2291\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4281 - val_loss: 1.0457\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5160 - val_loss: 0.9918\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4155 - val_loss: 0.9701\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5010 - val_loss: 1.0076\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4676 - val_loss: 1.0340\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4012 - val_loss: 0.9852\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4239 - val_loss: 0.9856\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4211 - val_loss: 1.0359\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4781 - val_loss: 1.3020\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7164 - val_loss: 1.3794\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6486 - val_loss: 1.0886\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4405 - val_loss: 0.9816\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3810 - val_loss: 0.9258\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3829 - val_loss: 0.9630\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4058 - val_loss: 1.0939\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3969 - val_loss: 0.9259\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5074 - val_loss: 0.9918\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6168 - val_loss: 0.9553\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4287 - val_loss: 0.9536\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3860 - val_loss: 0.9636\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5738 - val_loss: 0.9256\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4138 - val_loss: 0.9321\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3610 - val_loss: 0.8929\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3614 - val_loss: 0.8667\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3632 - val_loss: 0.8888\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3700 - val_loss: 0.8830\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4040 - val_loss: 0.8755\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3499 - val_loss: 0.8751\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3454 - val_loss: 0.8847\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3475 - val_loss: 0.8531\n",
            "[CV]  n_neurons=13, n_hidden=1, learning_rate=0.011535688495495584, total=   3.9s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 80.8596 - val_loss: 40.1370\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 31.9771 - val_loss: 8.5078\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.6479 - val_loss: 2.9043\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.8996 - val_loss: 2.5734\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7804 - val_loss: 2.4377\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6991 - val_loss: 2.4075\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.6377 - val_loss: 2.3712\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.5884 - val_loss: 2.3417\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5102 - val_loss: 2.0769\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.6826 - val_loss: 2.8769\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5738 - val_loss: 1.8625\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3601 - val_loss: 1.9961\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.3294 - val_loss: 1.7695\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3949 - val_loss: 1.6515\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.3578 - val_loss: 1.6803\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.2336 - val_loss: 1.8092\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2025 - val_loss: 1.6719\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1892 - val_loss: 1.8467\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1628 - val_loss: 1.6910\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.1807 - val_loss: 1.5377\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1395 - val_loss: 1.7257\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.2105 - val_loss: 1.9680\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2113 - val_loss: 1.7650\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.1038 - val_loss: 1.6881\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0531 - val_loss: 1.5153\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0615 - val_loss: 1.4844\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0285 - val_loss: 1.6188\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0191 - val_loss: 1.4793\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9999 - val_loss: 1.5692\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0279 - val_loss: 1.6657\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9945 - val_loss: 1.4866\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9690 - val_loss: 1.4505\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9846 - val_loss: 1.6360\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9697 - val_loss: 1.4450\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9423 - val_loss: 1.4737\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9313 - val_loss: 1.4627\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9299 - val_loss: 1.4006\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9429 - val_loss: 1.5739\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9574 - val_loss: 1.4993\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9100 - val_loss: 1.3757\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9046 - val_loss: 1.4736\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9076 - val_loss: 1.4648\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.8858 - val_loss: 1.3794\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8854 - val_loss: 1.3537\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8729 - val_loss: 1.3894\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8890 - val_loss: 1.4730\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9035 - val_loss: 1.4553\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9359 - val_loss: 1.5293\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8812 - val_loss: 1.3134\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8555 - val_loss: 1.3678\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8460 - val_loss: 1.3833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8447 - val_loss: 1.3768\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8350 - val_loss: 1.3021\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8338 - val_loss: 1.3108\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8207 - val_loss: 1.3218\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8168 - val_loss: 1.3118\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8255 - val_loss: 1.3861\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8268 - val_loss: 1.3370\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8067 - val_loss: 1.3180\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8003 - val_loss: 1.3053\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7957 - val_loss: 1.3003\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7950 - val_loss: 1.3193\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7902 - val_loss: 1.2787\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8001 - val_loss: 1.2529\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7924 - val_loss: 1.2696\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8099 - val_loss: 1.3753\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8041 - val_loss: 1.2322\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8195 - val_loss: 1.4089\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8249 - val_loss: 1.2851\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7700 - val_loss: 1.2337\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7655 - val_loss: 1.2477\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7609 - val_loss: 1.2577\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7609 - val_loss: 1.2566\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7553 - val_loss: 1.2240\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7799 - val_loss: 1.1945\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7735 - val_loss: 1.2040\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7471 - val_loss: 1.2304\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7444 - val_loss: 1.2256\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7570 - val_loss: 1.1864\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7491 - val_loss: 1.2165\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7391 - val_loss: 1.2358\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7584 - val_loss: 1.1842\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7512 - val_loss: 1.2649\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7367 - val_loss: 1.1991\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7247 - val_loss: 1.2058\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7264 - val_loss: 1.1810\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7262 - val_loss: 1.1853\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8388 - val_loss: 1.4430\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8125 - val_loss: 1.1848\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7136 - val_loss: 1.1815\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7134 - val_loss: 1.2092\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7121 - val_loss: 1.1695\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7097 - val_loss: 1.2043\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7075 - val_loss: 1.1639\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7175 - val_loss: 1.1524\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8148 - val_loss: 1.4245\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8088 - val_loss: 1.1645\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7115 - val_loss: 1.2121\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7093 - val_loss: 1.1705\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6920 - val_loss: 1.1456\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725, total=   3.9s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 83.1697 - val_loss: 44.0448\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 42.2527 - val_loss: 14.1689\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12.3553 - val_loss: 6.7978\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 6.2438 - val_loss: 5.8368\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.3354 - val_loss: 5.1583\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.8781 - val_loss: 5.0703\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.3924 - val_loss: 4.3110\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.2907 - val_loss: 3.9713\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.7257 - val_loss: 3.8159\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.4719 - val_loss: 4.0042\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.1898 - val_loss: 3.4012\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8640 - val_loss: 3.2668\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.7259 - val_loss: 2.9326\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5977 - val_loss: 2.8170\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.3883 - val_loss: 2.8472\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.2670 - val_loss: 2.7498\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1698 - val_loss: 2.6372\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1466 - val_loss: 2.8159\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.0414 - val_loss: 2.4607\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.2285 - val_loss: 2.2494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.9895 - val_loss: 2.5400\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8868 - val_loss: 2.5015\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.8546 - val_loss: 2.4692\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7528 - val_loss: 2.2928\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.6602 - val_loss: 2.1087\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.6935 - val_loss: 2.0017\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.6046 - val_loss: 2.1596\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.5457 - val_loss: 2.0480\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5168 - val_loss: 2.0968\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.5210 - val_loss: 2.1121\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4692 - val_loss: 1.9854\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4398 - val_loss: 2.0143\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.4851 - val_loss: 2.1570\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4377 - val_loss: 1.9160\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3625 - val_loss: 1.8986\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3359 - val_loss: 1.8449\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.3144 - val_loss: 1.7900\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.3082 - val_loss: 1.8984\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.2872 - val_loss: 1.7219\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3051 - val_loss: 1.6563\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2716 - val_loss: 1.6968\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.2330 - val_loss: 1.7959\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2183 - val_loss: 1.7055\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.1934 - val_loss: 1.6343\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1870 - val_loss: 1.7331\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.1967 - val_loss: 1.7211\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1605 - val_loss: 1.6181\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.1459 - val_loss: 1.6661\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1791 - val_loss: 1.5136\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1486 - val_loss: 1.6063\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1059 - val_loss: 1.5734\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.1320 - val_loss: 1.6862\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.1080 - val_loss: 1.4817\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0830 - val_loss: 1.5411\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0791 - val_loss: 1.4649\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0742 - val_loss: 1.4809\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0487 - val_loss: 1.5388\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0388 - val_loss: 1.4645\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0366 - val_loss: 1.5434\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.0286 - val_loss: 1.4312\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.0253 - val_loss: 1.5382\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.0213 - val_loss: 1.4756\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0053 - val_loss: 1.3965\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0355 - val_loss: 1.3753\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0710 - val_loss: 1.3577\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9961 - val_loss: 1.4528\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9715 - val_loss: 1.3669\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9668 - val_loss: 1.4476\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9758 - val_loss: 1.4360\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9761 - val_loss: 1.4424\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9633 - val_loss: 1.3095\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9467 - val_loss: 1.3606\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9252 - val_loss: 1.3517\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9351 - val_loss: 1.2904\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9388 - val_loss: 1.2993\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9136 - val_loss: 1.2975\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9060 - val_loss: 1.2930\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8998 - val_loss: 1.2871\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9013 - val_loss: 1.2728\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8895 - val_loss: 1.3182\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9574 - val_loss: 1.4662\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9179 - val_loss: 1.2655\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.8712 - val_loss: 1.2923\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8651 - val_loss: 1.2619\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8608 - val_loss: 1.2799\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8797 - val_loss: 1.2283\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8943 - val_loss: 1.2286\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8940 - val_loss: 1.4001\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8898 - val_loss: 1.2628\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8549 - val_loss: 1.2136\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8435 - val_loss: 1.2438\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8358 - val_loss: 1.2113\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8298 - val_loss: 1.2287\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8207 - val_loss: 1.2153\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8354 - val_loss: 1.1905\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8279 - val_loss: 1.2699\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8252 - val_loss: 1.2294\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8106 - val_loss: 1.2248\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8043 - val_loss: 1.2148\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.8041 - val_loss: 1.1733\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725, total=   5.5s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 116.4228 - val_loss: 88.7176\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 96.6884 - val_loss: 82.4637\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 90.0918 - val_loss: 77.7560\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 84.8246 - val_loss: 72.9957\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 79.2923 - val_loss: 66.8916\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 71.6231 - val_loss: 56.1784\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 57.0009 - val_loss: 36.1595\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 32.3294 - val_loss: 12.7663\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 9.7979 - val_loss: 3.8602\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.8562 - val_loss: 2.0856\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.9630 - val_loss: 1.9594\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.7454 - val_loss: 1.6351\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.5668 - val_loss: 1.6327\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4249 - val_loss: 1.5199\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3361 - val_loss: 1.5891\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.2442 - val_loss: 1.5065\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1335 - val_loss: 1.4355\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0334 - val_loss: 1.3559\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9576 - val_loss: 1.2857\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9848 - val_loss: 1.1815\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8933 - val_loss: 1.2278\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8072 - val_loss: 1.2189\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7799 - val_loss: 1.2742\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7387 - val_loss: 1.1956\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.7030 - val_loss: 1.1747\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6758 - val_loss: 1.1934\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6575 - val_loss: 1.2099\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6323 - val_loss: 1.1600\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6161 - val_loss: 1.1460\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6057 - val_loss: 1.2017\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5855 - val_loss: 1.1509\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5855 - val_loss: 1.2180\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5745 - val_loss: 1.1797\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5522 - val_loss: 1.1667\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5991 - val_loss: 1.2712\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5701 - val_loss: 1.1767\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5278 - val_loss: 1.1730\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5111 - val_loss: 1.1190\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4982 - val_loss: 1.1290\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4979 - val_loss: 1.1050\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4888 - val_loss: 1.1279\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4882 - val_loss: 1.1529\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4797 - val_loss: 1.1215\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4716 - val_loss: 1.1261\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4705 - val_loss: 1.1351\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4799 - val_loss: 1.1573\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4685 - val_loss: 1.1201\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4574 - val_loss: 1.1093\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4574 - val_loss: 1.1010\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4562 - val_loss: 1.0984\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4530 - val_loss: 1.1007\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4615 - val_loss: 1.1502\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4562 - val_loss: 1.1154\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4475 - val_loss: 1.1227\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4466 - val_loss: 1.1185\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4457 - val_loss: 1.1213\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4450 - val_loss: 1.0920\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4412 - val_loss: 1.1077\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4414 - val_loss: 1.1198\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4390 - val_loss: 1.1021\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4373 - val_loss: 1.0945\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4364 - val_loss: 1.0965\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4354 - val_loss: 1.0953\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4358 - val_loss: 1.1135\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4450 - val_loss: 1.0790\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4435 - val_loss: 1.0858\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4351 - val_loss: 1.0863\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4344 - val_loss: 1.0819\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4356 - val_loss: 1.0789\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4396 - val_loss: 1.1161\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4452 - val_loss: 1.0649\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4360 - val_loss: 1.0829\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4323 - val_loss: 1.0663\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4431 - val_loss: 1.0604\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4336 - val_loss: 1.0805\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4273 - val_loss: 1.0742\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4349 - val_loss: 1.0607\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4306 - val_loss: 1.0848\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4438 - val_loss: 1.1196\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4609 - val_loss: 1.1244\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4400 - val_loss: 1.0841\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4260 - val_loss: 1.0774\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4257 - val_loss: 1.0624\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4247 - val_loss: 1.0779\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.0052787610094815725, total=   5.5s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 105.0332 - val_loss: 67.6475\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 60.2558 - val_loss: 8.8772\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10.4581 - val_loss: 6.6590\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10.0950 - val_loss: 6.3806\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12.7183 - val_loss: 5.9936\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 9.8525 - val_loss: 4.2989\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 7.9355 - val_loss: 4.4880\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 7.2867 - val_loss: 3.9633\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 7.7242 - val_loss: 3.3281\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.2325 - val_loss: 2.3837\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.0653 - val_loss: 3.2058\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 5.9690 - val_loss: 3.2945\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10.5590 - val_loss: 5.3982\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 17.2201 - val_loss: 3.5106\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 8.1325 - val_loss: 3.9794\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 6.1682 - val_loss: 2.0001\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.1342 - val_loss: 3.4900\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 6.0142 - val_loss: 4.4480\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 7.2382 - val_loss: 3.9859\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.1032 - val_loss: 5.5979\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 7.4709 - val_loss: 4.0643\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.8010 - val_loss: 2.6603\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.8904 - val_loss: 1.9377\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.9301 - val_loss: 1.6712\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.1939 - val_loss: 2.3373\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.8698 - val_loss: 5.2181\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.1604 - val_loss: 2.9067\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.4334 - val_loss: 3.0399\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.4230 - val_loss: 3.2986\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 3.4080 - val_loss: 2.5423\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3147 - val_loss: 2.5837\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.2989 - val_loss: 3.1767\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.4689 - val_loss: 2.2772\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2439 - val_loss: 3.4740\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563, total=   2.9s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 101.9809 - val_loss: 76.9283\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 86.1934 - val_loss: 66.2129\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 74.9648 - val_loss: 56.9990\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 65.2661 - val_loss: 49.0990\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 56.8414 - val_loss: 42.1754\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 49.5205 - val_loss: 36.3903\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 43.2641 - val_loss: 31.3274\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 37.7563 - val_loss: 26.9001\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 33.0113 - val_loss: 23.3387\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 29.0819 - val_loss: 20.2824\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 25.6666 - val_loss: 17.6427\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 22.6878 - val_loss: 15.3686\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 20.1203 - val_loss: 13.4672\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 17.8997 - val_loss: 11.7894\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 15.9502 - val_loss: 10.3852\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 14.3029 - val_loss: 9.2230\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12.8642 - val_loss: 8.1623\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11.5936 - val_loss: 7.3282\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10.5419 - val_loss: 6.6123\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 9.6020 - val_loss: 5.9543\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.7472 - val_loss: 5.4262\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 8.0405 - val_loss: 4.9940\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 7.4502 - val_loss: 4.6467\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 6.9401 - val_loss: 4.3401\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.4856 - val_loss: 4.0881\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 6.0916 - val_loss: 3.8731\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.7663 - val_loss: 3.7222\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.4906 - val_loss: 3.5833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.2350 - val_loss: 3.4603\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.0007 - val_loss: 3.3704\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.8120 - val_loss: 3.2995\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.6504 - val_loss: 3.2461\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 4.5108 - val_loss: 3.2030\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.3968 - val_loss: 3.1774\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.2998 - val_loss: 3.1563\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.2139 - val_loss: 3.1428\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.1365 - val_loss: 3.1340\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0640 - val_loss: 3.1309\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0012 - val_loss: 3.1322\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9518 - val_loss: 3.1370\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.9094 - val_loss: 3.1435\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.8739 - val_loss: 3.1521\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.8414 - val_loss: 3.1649\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.8078 - val_loss: 3.1794\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.7815 - val_loss: 3.1903\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.7666 - val_loss: 3.1998\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7485 - val_loss: 3.2156\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 3.7325 - val_loss: 3.2262\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563, total=   2.4s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 70.8019 - val_loss: 4.4338\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 6.3444 - val_loss: 3.0143\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 8.1857 - val_loss: 5.7998\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.0789 - val_loss: 4.3772\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 7.7414 - val_loss: 10.6318\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 20.1128 - val_loss: 5.9117\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10.9088 - val_loss: 7.5341\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 15.8517 - val_loss: 4.6681\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.7628 - val_loss: 3.5268\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 6.8470 - val_loss: 5.0591\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 7.1693 - val_loss: 4.2392\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.9262 - val_loss: 4.6821\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.017987812090718563, total=   1.7s\n",
            "[CV] n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 43.4213 - val_loss: 6.8809\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 7.0400 - val_loss: 4.9054\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.3473 - val_loss: 4.2871\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0565 - val_loss: 3.9613\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.3885 - val_loss: 5.0520\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 5.5461 - val_loss: 5.9109\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.8047 - val_loss: 2.8761\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.1220 - val_loss: 4.4091\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6569 - val_loss: 2.5465\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5858 - val_loss: 3.7637\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.1605 - val_loss: 2.4418\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.3895 - val_loss: 3.1296\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2485 - val_loss: 1.9029\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5740 - val_loss: 1.8364\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5123 - val_loss: 1.7859\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4543 - val_loss: 1.9570\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3901 - val_loss: 1.7864\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.4801 - val_loss: 1.6783\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.2767 - val_loss: 1.7888\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2438 - val_loss: 1.7895\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2549 - val_loss: 1.7840\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.5464 - val_loss: 2.4026\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.9645 - val_loss: 2.0835\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5986 - val_loss: 1.8777\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.3042 - val_loss: 1.6180\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0880 - val_loss: 1.8434\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3489 - val_loss: 1.5805\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0414 - val_loss: 1.5496\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0152 - val_loss: 1.5253\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.0841 - val_loss: 2.1914\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.5637 - val_loss: 1.6637\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0982 - val_loss: 1.5225\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2226 - val_loss: 2.4173\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.4424 - val_loss: 1.3979\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.9400 - val_loss: 1.4507\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9703 - val_loss: 1.4289\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9297 - val_loss: 1.4095\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8896 - val_loss: 1.5939\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2274 - val_loss: 2.0153\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1653 - val_loss: 1.3552\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8531 - val_loss: 1.3761\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8603 - val_loss: 1.4828\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9137 - val_loss: 1.3846\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8359 - val_loss: 1.3345\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8375 - val_loss: 1.4587\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9795 - val_loss: 1.5592\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0265 - val_loss: 1.5285\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3251 - val_loss: 2.5195\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5394 - val_loss: 1.2890\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7853 - val_loss: 1.3378\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.8594 - val_loss: 1.4046\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9394 - val_loss: 1.5416\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9071 - val_loss: 1.3209\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7464 - val_loss: 1.2917\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7367 - val_loss: 1.2952\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7356 - val_loss: 1.2718\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7271 - val_loss: 1.2995\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8005 - val_loss: 1.4005\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7631 - val_loss: 1.2529\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7150 - val_loss: 1.2384\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7018 - val_loss: 1.2265\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7109 - val_loss: 1.3082\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7737 - val_loss: 1.2725\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6916 - val_loss: 1.2140\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7347 - val_loss: 1.1791\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6886 - val_loss: 1.4238\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7353 - val_loss: 1.2152\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6839 - val_loss: 1.6327\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0220 - val_loss: 1.2094\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6687 - val_loss: 1.1384\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6815 - val_loss: 1.1074\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6517 - val_loss: 1.1916\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8259 - val_loss: 1.4254\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8753 - val_loss: 1.1168\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6384 - val_loss: 1.0854\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7747 - val_loss: 1.1369\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7832 - val_loss: 1.0669\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6375 - val_loss: 1.0506\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6379 - val_loss: 1.1278\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7105 - val_loss: 1.0604\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6226 - val_loss: 1.0475\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6794 - val_loss: 1.3101\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7244 - val_loss: 1.0596\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6046 - val_loss: 1.0270\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5915 - val_loss: 1.0215\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5816 - val_loss: 0.9953\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5970 - val_loss: 0.9906\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7373 - val_loss: 2.3001\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.5462 - val_loss: 1.0891\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6552 - val_loss: 1.0126\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6492 - val_loss: 1.1670\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6357 - val_loss: 0.9740\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5533 - val_loss: 1.0303\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5605 - val_loss: 0.9622\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6071 - val_loss: 1.0125\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6198 - val_loss: 2.1037\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4720 - val_loss: 1.1203\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8373 - val_loss: 1.3134\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9370 - val_loss: 1.1777\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7407 - val_loss: 0.9646\n",
            "[CV]  n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244, total=   4.1s\n",
            "[CV] n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 92.7509 - val_loss: 49.2342\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 40.1414 - val_loss: 2.2409\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.4568 - val_loss: 2.0394\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 3.1789 - val_loss: 6.0884\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.5344 - val_loss: 2.1248\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.2554 - val_loss: 1.9389\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8483 - val_loss: 1.5620\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.4222 - val_loss: 2.3587\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5130 - val_loss: 1.3925\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3530 - val_loss: 2.0573\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.7863 - val_loss: 1.7693\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4411 - val_loss: 1.5379\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.2015 - val_loss: 1.3320\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0500 - val_loss: 1.3752\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0261 - val_loss: 1.2882\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9351 - val_loss: 1.2075\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8733 - val_loss: 1.1940\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8587 - val_loss: 1.2589\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9585 - val_loss: 1.4222\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8268 - val_loss: 1.4801\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1391 - val_loss: 1.1535\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.8116 - val_loss: 1.1407\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7641 - val_loss: 1.1650\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7713 - val_loss: 1.1576\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7566 - val_loss: 1.1910\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9209 - val_loss: 1.2322\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8564 - val_loss: 1.1217\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7840 - val_loss: 1.4486\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1528 - val_loss: 1.6359\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.3141 - val_loss: 1.6271\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0148 - val_loss: 1.1528\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7626 - val_loss: 1.3053\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9556 - val_loss: 1.4579\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8211 - val_loss: 1.1650\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7834 - val_loss: 1.1110\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7010 - val_loss: 1.1308\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.7300 - val_loss: 1.1357\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.8812 - val_loss: 1.6868\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0537 - val_loss: 1.0680\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7033 - val_loss: 1.1659\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8972 - val_loss: 1.1257\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8032 - val_loss: 1.1086\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7391 - val_loss: 1.0749\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7092 - val_loss: 1.0880\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6695 - val_loss: 1.1591\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8226 - val_loss: 1.2803\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7885 - val_loss: 1.0618\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6615 - val_loss: 1.0575\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6844 - val_loss: 1.2274\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7859 - val_loss: 1.0396\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6495 - val_loss: 1.0561\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6984 - val_loss: 1.1848\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6615 - val_loss: 1.1670\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7480 - val_loss: 1.0360\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6618 - val_loss: 1.0688\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6755 - val_loss: 1.0306\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6383 - val_loss: 1.0279\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6767 - val_loss: 1.1053\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6598 - val_loss: 1.0447\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6386 - val_loss: 1.0199\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6690 - val_loss: 1.2511\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7866 - val_loss: 1.0429\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6210 - val_loss: 1.0359\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7250 - val_loss: 1.2336\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0781 - val_loss: 1.2378\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8048 - val_loss: 1.0197\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7158 - val_loss: 1.1597\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7781 - val_loss: 1.0207\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6483 - val_loss: 1.0084\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6070 - val_loss: 1.0189\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6040 - val_loss: 1.1242\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6742 - val_loss: 0.9702\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6375 - val_loss: 1.0769\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6203 - val_loss: 0.9816\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6972 - val_loss: 1.0128\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7735 - val_loss: 1.0804\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8875 - val_loss: 1.1819\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8724 - val_loss: 1.0704\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7307 - val_loss: 0.9691\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5812 - val_loss: 1.0130\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8024 - val_loss: 1.5140\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9271 - val_loss: 0.9646\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5718 - val_loss: 0.9659\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5711 - val_loss: 0.9792\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5929 - val_loss: 0.9412\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6248 - val_loss: 1.1435\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.8918 - val_loss: 1.0182\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5774 - val_loss: 1.1376\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7603 - val_loss: 0.9917\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5702 - val_loss: 0.9885\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6050 - val_loss: 0.9234\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5605 - val_loss: 0.9343\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.5607 - val_loss: 0.9233\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5653 - val_loss: 0.9755\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7102 - val_loss: 1.0547\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6202 - val_loss: 0.9229\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5620 - val_loss: 0.9294\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6014 - val_loss: 0.9883\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6580 - val_loss: 0.9963\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6057 - val_loss: 0.9141\n",
            "[CV]  n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244, total=   4.2s\n",
            "[CV] n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244 .....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 95.3132 - val_loss: 78.4458\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 79.7234 - val_loss: 39.9507\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 31.1631 - val_loss: 5.1639\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 7.8468 - val_loss: 9.8568\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.1595 - val_loss: 3.5209\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 6.1458 - val_loss: 3.2607\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.6919 - val_loss: 2.9755\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.8693 - val_loss: 3.6477\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.5599 - val_loss: 2.1715\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.3508 - val_loss: 2.0397\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.1153 - val_loss: 3.2042\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.1146 - val_loss: 1.7657\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.5720 - val_loss: 1.7283\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3603 - val_loss: 1.6788\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2664 - val_loss: 2.0123\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2345 - val_loss: 1.5921\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9926 - val_loss: 1.6483\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9787 - val_loss: 1.6526\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8565 - val_loss: 1.3419\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8066 - val_loss: 1.5136\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0094 - val_loss: 1.2260\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6180 - val_loss: 1.2015\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5536 - val_loss: 1.3454\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5486 - val_loss: 1.1728\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5385 - val_loss: 1.1479\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5334 - val_loss: 1.1505\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4806 - val_loss: 1.2437\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.4828 - val_loss: 1.1201\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4632 - val_loss: 1.0988\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4520 - val_loss: 1.2053\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4708 - val_loss: 1.1310\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5043 - val_loss: 1.4741\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7285 - val_loss: 1.4149\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6429 - val_loss: 1.2092\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6832 - val_loss: 1.7779\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0037 - val_loss: 1.3647\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6849 - val_loss: 1.3311\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4881 - val_loss: 1.0445\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4286 - val_loss: 1.0485\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4522 - val_loss: 1.0711\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4803 - val_loss: 1.0478\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4313 - val_loss: 1.2571\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5086 - val_loss: 1.1057\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4405 - val_loss: 1.1226\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4591 - val_loss: 1.1320\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5049 - val_loss: 1.2506\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5220 - val_loss: 1.1022\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4116 - val_loss: 1.0267\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4142 - val_loss: 1.0339\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4072 - val_loss: 1.0214\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4201 - val_loss: 1.0176\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4103 - val_loss: 1.1953\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5010 - val_loss: 1.0938\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4508 - val_loss: 1.1376\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4672 - val_loss: 1.0885\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4523 - val_loss: 1.1509\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4187 - val_loss: 1.0183\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4191 - val_loss: 1.0259\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4051 - val_loss: 1.0949\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4208 - val_loss: 1.0313\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3977 - val_loss: 1.0097\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4084 - val_loss: 1.0062\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4019 - val_loss: 1.0050\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3997 - val_loss: 1.1036\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.3996 - val_loss: 1.0473\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5478 - val_loss: 1.0212\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.4897 - val_loss: 0.9937\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.4455 - val_loss: 0.9968\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4658 - val_loss: 1.0020\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4031 - val_loss: 1.1220\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4022 - val_loss: 1.0576\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4989 - val_loss: 0.9786\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4181 - val_loss: 0.9955\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5676 - val_loss: 1.0698\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5143 - val_loss: 1.0005\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3893 - val_loss: 0.9959\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4268 - val_loss: 1.0432\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4418 - val_loss: 1.0114\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4420 - val_loss: 1.2678\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7333 - val_loss: 1.4225\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6683 - val_loss: 1.0496\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4282 - val_loss: 1.0217\n",
            "[CV]  n_neurons=2, n_hidden=1, learning_rate=0.012434530062231244, total=   3.4s\n",
            "[CV] n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283 ..\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 165ms/step - loss: 125.0080 - val_loss: 102.6787\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 121.3657 - val_loss: 100.2714\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 117.9142 - val_loss: 98.1733\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 114.8134 - val_loss: 96.1569\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 111.9284 - val_loss: 94.1450\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 109.1639 - val_loss: 92.2782\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 106.5638 - val_loss: 90.4932\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 104.0119 - val_loss: 88.6464\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 101.4263 - val_loss: 86.7715\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 98.8534 - val_loss: 84.7577\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 96.1964 - val_loss: 82.8242\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 93.5061 - val_loss: 80.6787\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 90.6625 - val_loss: 78.6046\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 87.8615 - val_loss: 76.4359\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 84.8084 - val_loss: 74.1503\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 81.8065 - val_loss: 71.7129\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 78.7961 - val_loss: 69.1332\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 75.6215 - val_loss: 66.4116\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 72.3605 - val_loss: 63.6671\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 69.0725 - val_loss: 60.8589\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 65.7626 - val_loss: 58.0508\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 62.4614 - val_loss: 55.2458\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 59.1453 - val_loss: 52.4528\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 55.8653 - val_loss: 49.6799\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 52.6510 - val_loss: 46.9942\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 49.4810 - val_loss: 44.2414\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 46.3223 - val_loss: 41.5972\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 43.2922 - val_loss: 39.0304\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 40.3410 - val_loss: 36.4933\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 37.4488 - val_loss: 34.0522\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 34.7145 - val_loss: 31.7404\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 32.1267 - val_loss: 29.5176\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 29.6617 - val_loss: 27.4025\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 27.3071 - val_loss: 25.3354\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 25.0568 - val_loss: 23.4076\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 22.9632 - val_loss: 21.5913\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 20.9969 - val_loss: 19.8364\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 19.1645 - val_loss: 18.2986\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 17.5291 - val_loss: 16.8227\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 15.9863 - val_loss: 15.4118\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 14.5475 - val_loss: 14.1429\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13.2983 - val_loss: 13.0686\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.2071 - val_loss: 12.0445\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11.2058 - val_loss: 11.1227\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 10.3047 - val_loss: 10.2504\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 9.4911 - val_loss: 9.5081\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.7931 - val_loss: 8.8271\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.1819 - val_loss: 8.2431\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 7.6628 - val_loss: 7.7279\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 7.1994 - val_loss: 7.2430\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.7896 - val_loss: 6.8278\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.4237 - val_loss: 6.4172\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 6.0927 - val_loss: 6.0701\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.8068 - val_loss: 5.7210\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.5371 - val_loss: 5.4328\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.3188 - val_loss: 5.1581\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.1254 - val_loss: 4.9585\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.9824 - val_loss: 4.7815\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.8516 - val_loss: 4.6031\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.7311 - val_loss: 4.4466\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 4.6268 - val_loss: 4.2995\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.5380 - val_loss: 4.1883\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.4604 - val_loss: 4.0692\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.3879 - val_loss: 3.9688\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.3267 - val_loss: 3.8681\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.2701 - val_loss: 3.7936\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.2260 - val_loss: 3.7027\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.1823 - val_loss: 3.6580\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.1458 - val_loss: 3.6030\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.1127 - val_loss: 3.5549\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0836 - val_loss: 3.5113\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.0553 - val_loss: 3.4703\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 4.0276 - val_loss: 3.4253\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.0005 - val_loss: 3.3763\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9742 - val_loss: 3.3374\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.9526 - val_loss: 3.2879\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9252 - val_loss: 3.2636\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9104 - val_loss: 3.2481\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.8870 - val_loss: 3.2106\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.8654 - val_loss: 3.1754\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.8425 - val_loss: 3.1440\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.8317 - val_loss: 3.1008\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.8014 - val_loss: 3.0880\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.7848 - val_loss: 3.0750\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.7702 - val_loss: 3.0654\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.7569 - val_loss: 3.0592\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.7371 - val_loss: 3.0340\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7218 - val_loss: 3.0270\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7029 - val_loss: 3.0082\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 3.7072 - val_loss: 2.9637\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.6702 - val_loss: 2.9600\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6561 - val_loss: 2.9317\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6355 - val_loss: 2.9098\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6177 - val_loss: 2.8903\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5997 - val_loss: 2.8770\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.5840 - val_loss: 2.8675\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.5669 - val_loss: 2.8546\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.5517 - val_loss: 2.8392\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.5401 - val_loss: 2.8412\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.5222 - val_loss: 2.8239\n",
            "[CV]  n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283, total=   4.2s\n",
            "[CV] n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283 ..\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 165ms/step - loss: 103.5427 - val_loss: 89.3045\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 100.4199 - val_loss: 86.5728\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 97.3933 - val_loss: 83.9336\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 94.4653 - val_loss: 81.3275\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 91.5131 - val_loss: 78.6436\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 88.5227 - val_loss: 76.0749\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 85.6266 - val_loss: 73.5190\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 82.7231 - val_loss: 70.8845\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 79.7950 - val_loss: 68.3807\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 76.9594 - val_loss: 65.8850\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 74.1223 - val_loss: 63.3740\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 71.2732 - val_loss: 60.8188\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 68.3899 - val_loss: 58.2654\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 65.4547 - val_loss: 55.6286\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 62.4742 - val_loss: 52.9989\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 59.5407 - val_loss: 50.4153\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 56.5945 - val_loss: 47.6924\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 53.5952 - val_loss: 45.0856\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 50.6482 - val_loss: 42.4764\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 47.6741 - val_loss: 39.8108\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 44.6738 - val_loss: 37.2347\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 41.7860 - val_loss: 34.7892\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 39.0450 - val_loss: 32.4644\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 36.3684 - val_loss: 30.1508\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 33.7318 - val_loss: 27.9536\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 31.2086 - val_loss: 25.8474\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 28.8505 - val_loss: 23.9470\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 26.6585 - val_loss: 22.0896\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 24.5332 - val_loss: 20.2869\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 22.5028 - val_loss: 18.6715\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 20.6699 - val_loss: 17.1695\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 18.9817 - val_loss: 15.8159\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 17.4481 - val_loss: 14.5657\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 16.0735 - val_loss: 13.4863\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.8393 - val_loss: 12.4710\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13.7088 - val_loss: 11.5626\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12.6751 - val_loss: 10.6909\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11.7216 - val_loss: 9.9465\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 10.9033 - val_loss: 9.2853\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10.1717 - val_loss: 8.6859\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 9.5151 - val_loss: 8.1575\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 8.9505 - val_loss: 7.7138\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.4479 - val_loss: 7.2853\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.9857 - val_loss: 6.9178\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 7.6019 - val_loss: 6.6198\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.2753 - val_loss: 6.3503\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.9716 - val_loss: 6.0862\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.7052 - val_loss: 5.8838\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 6.4725 - val_loss: 5.6678\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 6.2485 - val_loss: 5.4957\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 6.0631 - val_loss: 5.3380\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.8954 - val_loss: 5.2013\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.7502 - val_loss: 5.0536\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 5.5940 - val_loss: 4.9336\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.4738 - val_loss: 4.8417\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.3757 - val_loss: 4.7409\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.2715 - val_loss: 4.6672\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.1878 - val_loss: 4.5907\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.1075 - val_loss: 4.5244\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.0359 - val_loss: 4.4618\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.9678 - val_loss: 4.3966\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.8978 - val_loss: 4.3382\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.8439 - val_loss: 4.2738\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.7685 - val_loss: 4.2281\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.7146 - val_loss: 4.1828\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 4.6626 - val_loss: 4.1372\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.6110 - val_loss: 4.0969\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.5639 - val_loss: 4.0591\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.5176 - val_loss: 4.0218\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.4777 - val_loss: 3.9892\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 4.4311 - val_loss: 3.9563\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3906 - val_loss: 3.9158\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3434 - val_loss: 3.8796\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3043 - val_loss: 3.8512\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 4.2614 - val_loss: 3.8177\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.2201 - val_loss: 3.7863\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.1832 - val_loss: 3.7580\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.1491 - val_loss: 3.7330\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.1114 - val_loss: 3.7039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.0786 - val_loss: 3.6810\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.0475 - val_loss: 3.6584\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.0161 - val_loss: 3.6258\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.9795 - val_loss: 3.5939\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9373 - val_loss: 3.5668\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.9065 - val_loss: 3.5432\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.8700 - val_loss: 3.5149\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.8338 - val_loss: 3.4898\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.8052 - val_loss: 3.4688\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.7751 - val_loss: 3.4480\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.7460 - val_loss: 3.4163\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.7035 - val_loss: 3.3905\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.6717 - val_loss: 3.3669\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3.6412 - val_loss: 3.3385\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.6110 - val_loss: 3.3124\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.5797 - val_loss: 3.2841\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.5448 - val_loss: 3.2630\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.5155 - val_loss: 3.2418\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.4820 - val_loss: 3.2213\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.4555 - val_loss: 3.2039\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.4313 - val_loss: 3.1783\n",
            "[CV]  n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283, total=   5.1s\n",
            "[CV] n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283 ..\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 178ms/step - loss: 72.0566 - val_loss: 65.9918\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 69.6966 - val_loss: 63.8902\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 67.3106 - val_loss: 61.8002\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 64.9062 - val_loss: 59.6444\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 62.4191 - val_loss: 57.3895\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 59.8552 - val_loss: 55.1165\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 57.2763 - val_loss: 52.8308\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 54.7039 - val_loss: 50.5571\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 52.1519 - val_loss: 48.2910\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 49.6170 - val_loss: 46.0443\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 47.1124 - val_loss: 43.8040\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 44.6152 - val_loss: 41.5496\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 42.1336 - val_loss: 39.3550\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 39.7173 - val_loss: 37.1853\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 37.3391 - val_loss: 35.0299\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 35.0165 - val_loss: 32.9364\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 32.7610 - val_loss: 30.9079\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 30.6012 - val_loss: 28.9677\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 28.5718 - val_loss: 27.1555\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 26.6106 - val_loss: 25.2928\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 24.6594 - val_loss: 23.5032\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 22.8265 - val_loss: 21.8849\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 21.1523 - val_loss: 20.3378\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.5915 - val_loss: 18.9308\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 18.1431 - val_loss: 17.5573\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 16.7833 - val_loss: 16.3322\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 15.5476 - val_loss: 15.1616\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 14.3887 - val_loss: 14.0655\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13.3140 - val_loss: 13.0414\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12.3361 - val_loss: 12.1260\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11.4529 - val_loss: 11.2536\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 10.6427 - val_loss: 10.4934\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 9.9365 - val_loss: 9.7962\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 9.3103 - val_loss: 9.1963\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 8.8059 - val_loss: 8.7065\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.3256 - val_loss: 8.2031\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 7.8791 - val_loss: 7.7432\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 7.4739 - val_loss: 7.3084\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 7.1105 - val_loss: 6.9428\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 6.7908 - val_loss: 6.5901\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 6.5055 - val_loss: 6.2933\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 6.2558 - val_loss: 6.0091\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.0209 - val_loss: 5.7414\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.8041 - val_loss: 5.5007\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.6260 - val_loss: 5.3171\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.4832 - val_loss: 5.1621\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.3415 - val_loss: 4.9788\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.2140 - val_loss: 4.8503\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.1038 - val_loss: 4.6809\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.9757 - val_loss: 4.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.8702 - val_loss: 4.4293\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.8036 - val_loss: 4.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.7235 - val_loss: 4.2634\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.6510 - val_loss: 4.1735\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.5907 - val_loss: 4.1142\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.5328 - val_loss: 4.0337\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.4714 - val_loss: 3.9632\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 4.4166 - val_loss: 3.9060\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 4.3700 - val_loss: 3.8551\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.3263 - val_loss: 3.8026\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 4.2857 - val_loss: 3.7555\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.2451 - val_loss: 3.7065\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.2033 - val_loss: 3.6738\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.1654 - val_loss: 3.6280\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.1236 - val_loss: 3.5975\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 4.0916 - val_loss: 3.5729\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.0657 - val_loss: 3.5574\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.0325 - val_loss: 3.5177\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.9965 - val_loss: 3.4858\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.9674 - val_loss: 3.4671\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.9377 - val_loss: 3.4430\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.9096 - val_loss: 3.4233\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.8813 - val_loss: 3.3989\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.8527 - val_loss: 3.3801\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.8249 - val_loss: 3.3626\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7998 - val_loss: 3.3496\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.7724 - val_loss: 3.3249\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 3.7426 - val_loss: 3.3050\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7188 - val_loss: 3.2944\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.6918 - val_loss: 3.2853\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.6796 - val_loss: 3.2855\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.6427 - val_loss: 3.2709\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.6196 - val_loss: 3.2421\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.5891 - val_loss: 3.2244\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5658 - val_loss: 3.2140\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.5444 - val_loss: 3.1870\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.5146 - val_loss: 3.1673\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.4890 - val_loss: 3.1555\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.4685 - val_loss: 3.1485\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.4491 - val_loss: 3.1247\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.4283 - val_loss: 3.1018\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.4005 - val_loss: 3.0947\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.3764 - val_loss: 3.0818\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3568 - val_loss: 3.0626\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.3319 - val_loss: 3.0487\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.3095 - val_loss: 3.0378\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.2870 - val_loss: 3.0285\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.2658 - val_loss: 3.0172\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.2476 - val_loss: 3.0141\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.2227 - val_loss: 2.9995\n",
            "[CV]  n_neurons=11, n_hidden=1, learning_rate=0.00032000958007244283, total=   5.7s\n",
            "[CV] n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 91.5933 - val_loss: 72.4845\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 82.8980 - val_loss: 65.7848\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 74.8919 - val_loss: 59.8492\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 67.7687 - val_loss: 54.4591\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 61.3221 - val_loss: 49.5773\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 55.5195 - val_loss: 45.2290\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 50.3357 - val_loss: 41.2976\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 45.6328 - val_loss: 37.6659\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 41.3669 - val_loss: 34.4950\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 37.5887 - val_loss: 31.5635\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 34.1524 - val_loss: 28.9556\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 31.0793 - val_loss: 26.5609\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 28.2797 - val_loss: 24.4165\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 25.7782 - val_loss: 22.4649\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 23.5216 - val_loss: 20.7187\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 21.5130 - val_loss: 19.1656\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 19.7114 - val_loss: 17.7468\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 18.0779 - val_loss: 16.4559\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 16.5951 - val_loss: 15.2743\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 15.2426 - val_loss: 14.1832\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14.0096 - val_loss: 13.2100\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12.9291 - val_loss: 12.3701\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 11.9759 - val_loss: 11.5915\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11.0983 - val_loss: 10.8704\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 10.2961 - val_loss: 10.2151\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 9.5622 - val_loss: 9.5887\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.8895 - val_loss: 9.0623\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.3055 - val_loss: 8.5585\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.7557 - val_loss: 8.0907\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 7.2582 - val_loss: 7.6878\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 6.8320 - val_loss: 7.3289\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 6.4511 - val_loss: 6.9988\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 6.1165 - val_loss: 6.7186\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 5.8088 - val_loss: 6.4372\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 5.5151 - val_loss: 6.1751\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 5.2452 - val_loss: 5.9341\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.9974 - val_loss: 5.6946\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.7644 - val_loss: 5.5082\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.5735 - val_loss: 5.3276\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3920 - val_loss: 5.1504\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.2207 - val_loss: 4.9990\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0803 - val_loss: 4.8720\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.9498 - val_loss: 4.7387\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.8231 - val_loss: 4.6163\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.7080 - val_loss: 4.5045\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.6055 - val_loss: 4.4057\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.5163 - val_loss: 4.3184\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.4425 - val_loss: 4.2451\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.3650 - val_loss: 4.1607\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.2934 - val_loss: 4.0905\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2277 - val_loss: 4.0211\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.1645 - val_loss: 3.9512\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.1036 - val_loss: 3.8799\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0427 - val_loss: 3.8134\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.9868 - val_loss: 3.7588\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9406 - val_loss: 3.7043\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.9032 - val_loss: 3.6676\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8647 - val_loss: 3.6259\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.8296 - val_loss: 3.5859\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.7947 - val_loss: 3.5437\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.7602 - val_loss: 3.5033\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.7287 - val_loss: 3.4694\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.7002 - val_loss: 3.4297\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.6687 - val_loss: 3.3970\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6430 - val_loss: 3.3672\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6191 - val_loss: 3.3409\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.5970 - val_loss: 3.3067\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5762 - val_loss: 3.2884\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.5555 - val_loss: 3.2671\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5344 - val_loss: 3.2431\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.5154 - val_loss: 3.2205\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4952 - val_loss: 3.1964\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.4761 - val_loss: 3.1725\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4574 - val_loss: 3.1515\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4403 - val_loss: 3.1272\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.4220 - val_loss: 3.1042\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4070 - val_loss: 3.0901\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.3914 - val_loss: 3.0739\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.3787 - val_loss: 3.0519\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.3620 - val_loss: 3.0334\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3474 - val_loss: 3.0171\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.3380 - val_loss: 2.9957\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.3193 - val_loss: 2.9812\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.3066 - val_loss: 2.9675\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2946 - val_loss: 2.9547\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.2834 - val_loss: 2.9432\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2718 - val_loss: 2.9268\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.2644 - val_loss: 2.9202\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2489 - val_loss: 2.9081\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.2404 - val_loss: 2.8895\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2243 - val_loss: 2.8774\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2131 - val_loss: 2.8621\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2003 - val_loss: 2.8498\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1902 - val_loss: 2.8355\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.1783 - val_loss: 2.8215\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.1682 - val_loss: 2.8143\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1576 - val_loss: 2.8034\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1466 - val_loss: 2.7942\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.1366 - val_loss: 2.7853\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.1277 - val_loss: 2.7711\n",
            "[CV]  n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959, total=   4.5s\n",
            "[CV] n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 91.7415 - val_loss: 77.5262\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 83.4671 - val_loss: 70.9083\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 75.9664 - val_loss: 64.9269\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 69.1998 - val_loss: 59.4767\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 63.0068 - val_loss: 54.3863\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 57.3707 - val_loss: 49.9349\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 52.3763 - val_loss: 45.8284\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 47.7736 - val_loss: 41.9842\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 43.6046 - val_loss: 38.7251\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 40.0096 - val_loss: 35.7544\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 36.7452 - val_loss: 33.0316\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 33.7622 - val_loss: 30.5322\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 31.0608 - val_loss: 28.2880\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 28.6123 - val_loss: 26.2000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 26.3824 - val_loss: 24.3344\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 24.4051 - val_loss: 22.6712\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 22.6056 - val_loss: 21.0769\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.9493 - val_loss: 19.6949\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 19.4978 - val_loss: 18.4329\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 18.1501 - val_loss: 17.1638\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 16.8499 - val_loss: 16.0914\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 15.7565 - val_loss: 15.1398\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 14.7891 - val_loss: 14.2808\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13.9056 - val_loss: 13.4696\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 13.0922 - val_loss: 12.7363\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12.3511 - val_loss: 12.0398\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11.6849 - val_loss: 11.4600\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11.0942 - val_loss: 10.8870\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 10.5311 - val_loss: 10.3435\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10.0142 - val_loss: 9.8756\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 9.5620 - val_loss: 9.4347\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 9.1509 - val_loss: 9.0468\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.7853 - val_loss: 8.6895\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.4671 - val_loss: 8.3869\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.1761 - val_loss: 8.0913\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.9014 - val_loss: 7.8103\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.6391 - val_loss: 7.5264\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 7.3892 - val_loss: 7.2876\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.1744 - val_loss: 7.0624\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 6.9734 - val_loss: 6.8478\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 6.7866 - val_loss: 6.6526\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 6.6242 - val_loss: 6.4861\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 6.4738 - val_loss: 6.3179\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 6.3293 - val_loss: 6.1600\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 6.2028 - val_loss: 6.0312\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 6.0929 - val_loss: 5.9106\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 5.9831 - val_loss: 5.7778\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.8821 - val_loss: 5.6759\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 5.7895 - val_loss: 5.5519\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.6897 - val_loss: 5.4505\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 5.6064 - val_loss: 5.3559\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.5295 - val_loss: 5.2737\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.4599 - val_loss: 5.1752\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 5.3814 - val_loss: 5.0904\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.3161 - val_loss: 5.0186\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.2601 - val_loss: 4.9365\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.1967 - val_loss: 4.8789\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.1464 - val_loss: 4.8171\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.0974 - val_loss: 4.7621\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 5.0520 - val_loss: 4.7056\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 5.0070 - val_loss: 4.6507\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.9623 - val_loss: 4.6006\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 4.9219 - val_loss: 4.5424\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 4.8751 - val_loss: 4.4968\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.8372 - val_loss: 4.4502\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.7992 - val_loss: 4.4111\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.7654 - val_loss: 4.3749\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.7330 - val_loss: 4.3415\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.7027 - val_loss: 4.3109\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.6733 - val_loss: 4.2824\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.6440 - val_loss: 4.2532\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.6161 - val_loss: 4.2149\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.5838 - val_loss: 4.1806\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 4.5560 - val_loss: 4.1575\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.5280 - val_loss: 4.1287\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.5015 - val_loss: 4.1045\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.4768 - val_loss: 4.0795\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.4525 - val_loss: 4.0580\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 4.4271 - val_loss: 4.0316\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 4.4036 - val_loss: 4.0117\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.3853 - val_loss: 3.9982\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.3614 - val_loss: 3.9680\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.3377 - val_loss: 3.9361\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3079 - val_loss: 3.9115\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.2871 - val_loss: 3.8971\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.2632 - val_loss: 3.8726\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.2391 - val_loss: 3.8526\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.2215 - val_loss: 3.8413\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4.2004 - val_loss: 3.8282\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.1824 - val_loss: 3.7989\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 4.1541 - val_loss: 3.7773\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 4.1324 - val_loss: 3.7569\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 4.1121 - val_loss: 3.7332\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.0890 - val_loss: 3.7119\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.0703 - val_loss: 3.6871\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.0450 - val_loss: 3.6707\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0255 - val_loss: 3.6582\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.0047 - val_loss: 3.6430\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.9870 - val_loss: 3.6321\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.9733 - val_loss: 3.6077\n",
            "[CV]  n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959, total=   4.4s\n",
            "[CV] n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 49.3467 - val_loss: 46.2716\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 45.1400 - val_loss: 42.6819\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 41.3602 - val_loss: 39.4523\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 37.9309 - val_loss: 36.4618\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 34.7386 - val_loss: 33.5877\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 31.7522 - val_loss: 31.0286\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 29.0921 - val_loss: 28.7110\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 26.6867 - val_loss: 26.5845\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 24.5161 - val_loss: 24.7126\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 22.5964 - val_loss: 23.0062\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 20.8632 - val_loss: 21.4646\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 19.2833 - val_loss: 20.0143\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 17.8258 - val_loss: 18.7036\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 16.5132 - val_loss: 17.5100\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 15.3296 - val_loss: 16.4345\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 14.2645 - val_loss: 15.4491\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 13.2979 - val_loss: 14.5604\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12.4295 - val_loss: 13.7495\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11.6470 - val_loss: 13.0159\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10.9162 - val_loss: 12.2800\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10.2142 - val_loss: 11.6155\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 9.5938 - val_loss: 11.0409\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 9.0485 - val_loss: 10.5041\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 8.5525 - val_loss: 10.0248\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 8.1014 - val_loss: 9.5618\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 7.6877 - val_loss: 9.1699\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 7.3212 - val_loss: 8.7878\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.9742 - val_loss: 8.4279\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 6.6523 - val_loss: 8.1000\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 6.3623 - val_loss: 7.7984\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 6.0959 - val_loss: 7.5113\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 5.8513 - val_loss: 7.2663\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.6424 - val_loss: 7.0450\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 5.4581 - val_loss: 6.8504\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 5.3059 - val_loss: 6.6861\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 5.1507 - val_loss: 6.5098\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 5.0046 - val_loss: 6.3475\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.8676 - val_loss: 6.1835\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.7364 - val_loss: 6.0424\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.6213 - val_loss: 5.9091\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.5174 - val_loss: 5.7904\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.4233 - val_loss: 5.6795\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.3302 - val_loss: 5.5599\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 4.2373 - val_loss: 5.4540\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.1594 - val_loss: 5.3653\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.0908 - val_loss: 5.2841\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0241 - val_loss: 5.1927\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.9611 - val_loss: 5.1240\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.9054 - val_loss: 5.0356\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.8398 - val_loss: 4.9577\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.7826 - val_loss: 4.8914\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.7446 - val_loss: 4.8483\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.7010 - val_loss: 4.7938\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.6608 - val_loss: 4.7368\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.6232 - val_loss: 4.6936\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.5878 - val_loss: 4.6389\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.5494 - val_loss: 4.5912\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.5158 - val_loss: 4.5504\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.4860 - val_loss: 4.5115\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.4582 - val_loss: 4.4698\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.4295 - val_loss: 4.4321\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4022 - val_loss: 4.3938\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.3750 - val_loss: 4.3614\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.3508 - val_loss: 4.3258\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.3252 - val_loss: 4.2981\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.3052 - val_loss: 4.2743\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.2882 - val_loss: 4.2550\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.2670 - val_loss: 4.2237\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.2441 - val_loss: 4.1972\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.2267 - val_loss: 4.1777\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.2071 - val_loss: 4.1518\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.1885 - val_loss: 4.1312\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1703 - val_loss: 4.1068\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.1523 - val_loss: 4.0885\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.1369 - val_loss: 4.0728\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.1232 - val_loss: 4.0595\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.1065 - val_loss: 4.0384\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.0897 - val_loss: 4.0204\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0738 - val_loss: 4.0048\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0586 - val_loss: 3.9902\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0514 - val_loss: 3.9829\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.0327 - val_loss: 3.9692\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.0180 - val_loss: 3.9472\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.0004 - val_loss: 3.9312\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.9866 - val_loss: 3.9179\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.9752 - val_loss: 3.8948\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9563 - val_loss: 3.8769\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9413 - val_loss: 3.8634\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.9295 - val_loss: 3.8533\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 2.9174 - val_loss: 3.8353\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9076 - val_loss: 3.8147\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.8887 - val_loss: 3.8031\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.8756 - val_loss: 3.7903\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8626 - val_loss: 3.7760\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.8489 - val_loss: 3.7641\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.8364 - val_loss: 3.7506\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.8234 - val_loss: 3.7403\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.8119 - val_loss: 3.7283\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.8006 - val_loss: 3.7198\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.7881 - val_loss: 3.7054\n",
            "[CV]  n_neurons=12, n_hidden=0, learning_rate=0.0009541386271682959, total=   4.4s\n",
            "[CV] n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 74.0611 - val_loss: 39.1385\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 42.2521 - val_loss: 23.3634\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 24.5480 - val_loss: 15.0510\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 15.1969 - val_loss: 10.4655\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 10.0484 - val_loss: 7.8040\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 7.1927 - val_loss: 6.3877\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.6270 - val_loss: 5.4665\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.6591 - val_loss: 4.8738\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.0669 - val_loss: 4.5026\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.7303 - val_loss: 4.2681\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4740 - val_loss: 4.0469\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.2676 - val_loss: 3.8533\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.0915 - val_loss: 3.6933\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.9469 - val_loss: 3.5730\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.8358 - val_loss: 3.4696\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.7330 - val_loss: 3.3667\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.6312 - val_loss: 3.2751\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.5452 - val_loss: 3.1939\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4563 - val_loss: 3.1096\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.3893 - val_loss: 3.0146\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2938 - val_loss: 2.9423\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.2437 - val_loss: 2.9005\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1580 - val_loss: 2.8425\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.0944 - val_loss: 2.7775\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0360 - val_loss: 2.7175\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.9934 - val_loss: 2.6480\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9288 - val_loss: 2.6049\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.8793 - val_loss: 2.5421\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.8263 - val_loss: 2.4911\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7853 - val_loss: 2.4657\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7428 - val_loss: 2.4254\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.7035 - val_loss: 2.3933\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.6973 - val_loss: 2.3821\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6365 - val_loss: 2.3414\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6065 - val_loss: 2.3031\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.5763 - val_loss: 2.2697\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5582 - val_loss: 2.2196\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5276 - val_loss: 2.2118\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.4946 - val_loss: 2.1835\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.4698 - val_loss: 2.1473\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.4435 - val_loss: 2.1284\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.4276 - val_loss: 2.1172\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.4008 - val_loss: 2.0874\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3792 - val_loss: 2.0582\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3573 - val_loss: 2.0366\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3422 - val_loss: 2.0255\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3281 - val_loss: 2.0157\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3259 - val_loss: 2.0152\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2963 - val_loss: 1.9792\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.2794 - val_loss: 1.9627\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2612 - val_loss: 1.9469\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.2468 - val_loss: 1.9277\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2369 - val_loss: 1.8982\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2225 - val_loss: 1.8748\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2088 - val_loss: 1.8623\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1997 - val_loss: 1.8467\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1955 - val_loss: 1.8496\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1776 - val_loss: 1.8408\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1680 - val_loss: 1.8298\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1580 - val_loss: 1.8139\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1481 - val_loss: 1.7998\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1396 - val_loss: 1.7925\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1319 - val_loss: 1.7740\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.1242 - val_loss: 1.7576\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1150 - val_loss: 1.7480\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.1115 - val_loss: 1.7520\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1080 - val_loss: 1.7252\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1069 - val_loss: 1.7380\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0882 - val_loss: 1.7329\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0799 - val_loss: 1.7176\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0734 - val_loss: 1.7082\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0663 - val_loss: 1.6990\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0600 - val_loss: 1.6885\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0547 - val_loss: 1.6762\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0540 - val_loss: 1.6561\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0449 - val_loss: 1.6452\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0400 - val_loss: 1.6469\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0345 - val_loss: 1.6450\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.0362 - val_loss: 1.6270\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0267 - val_loss: 1.6236\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0229 - val_loss: 1.6238\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0303 - val_loss: 1.6044\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0185 - val_loss: 1.6114\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0112 - val_loss: 1.6059\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0079 - val_loss: 1.6041\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0045 - val_loss: 1.5967\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0022 - val_loss: 1.5884\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0246 - val_loss: 1.6126\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9967 - val_loss: 1.5998\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9944 - val_loss: 1.5836\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9896 - val_loss: 1.5837\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9873 - val_loss: 1.5716\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9830 - val_loss: 1.5704\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9813 - val_loss: 1.5602\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9798 - val_loss: 1.5497\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9959 - val_loss: 1.5717\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9739 - val_loss: 1.5613\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9733 - val_loss: 1.5631\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9685 - val_loss: 1.5576\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9666 - val_loss: 1.5439\n",
            "[CV]  n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725, total=   4.2s\n",
            "[CV] n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 137.5956 - val_loss: 80.6987\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 77.9626 - val_loss: 48.2668\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 44.9959 - val_loss: 29.6412\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 26.8361 - val_loss: 19.2036\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16.7403 - val_loss: 12.6400\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 10.9460 - val_loss: 9.0286\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 7.8446 - val_loss: 6.7739\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 6.0368 - val_loss: 5.2106\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.9306 - val_loss: 4.4856\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.4421 - val_loss: 4.0373\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.0980 - val_loss: 3.6524\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.8434 - val_loss: 3.3682\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.6608 - val_loss: 3.1546\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.5172 - val_loss: 2.9946\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.3991 - val_loss: 2.8853\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3022 - val_loss: 2.8058\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.2137 - val_loss: 2.6999\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.1206 - val_loss: 2.6471\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.0502 - val_loss: 2.6111\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.0452 - val_loss: 2.4623\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.8858 - val_loss: 2.4293\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.8166 - val_loss: 2.4090\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.7486 - val_loss: 2.3840\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.6820 - val_loss: 2.3414\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.6139 - val_loss: 2.3090\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.5515 - val_loss: 2.2568\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.4968 - val_loss: 2.2428\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.4344 - val_loss: 2.2082\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.3791 - val_loss: 2.1720\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.3324 - val_loss: 2.1542\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2780 - val_loss: 2.1032\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2291 - val_loss: 2.0872\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.1805 - val_loss: 2.0670\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.1382 - val_loss: 2.0518\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.0980 - val_loss: 2.0375\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.0453 - val_loss: 2.0051\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.0038 - val_loss: 1.9588\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.9680 - val_loss: 1.9511\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.9249 - val_loss: 1.9121\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.8860 - val_loss: 1.8743\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8491 - val_loss: 1.8453\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.8137 - val_loss: 1.8277\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7803 - val_loss: 1.8128\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.7452 - val_loss: 1.7889\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.7175 - val_loss: 1.7875\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.6888 - val_loss: 1.7837\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.6564 - val_loss: 1.7485\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.6279 - val_loss: 1.7415\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.6124 - val_loss: 1.6985\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.5725 - val_loss: 1.6876\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.5454 - val_loss: 1.6761\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.5222 - val_loss: 1.6724\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5065 - val_loss: 1.6370\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4752 - val_loss: 1.6232\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.4556 - val_loss: 1.6078\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.4382 - val_loss: 1.5893\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.4135 - val_loss: 1.5854\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3954 - val_loss: 1.5722\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3768 - val_loss: 1.5728\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.3578 - val_loss: 1.5612\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3411 - val_loss: 1.5579\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3228 - val_loss: 1.5456\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3064 - val_loss: 1.5287\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.2901 - val_loss: 1.5133\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.2785 - val_loss: 1.4951\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2571 - val_loss: 1.4937\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2423 - val_loss: 1.4841\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2268 - val_loss: 1.4804\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2131 - val_loss: 1.4775\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.2001 - val_loss: 1.4755\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1863 - val_loss: 1.4626\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1736 - val_loss: 1.4560\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1620 - val_loss: 1.4481\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1504 - val_loss: 1.4401\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.1419 - val_loss: 1.4264\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.1300 - val_loss: 1.4184\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.1206 - val_loss: 1.4107\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1109 - val_loss: 1.4113\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1002 - val_loss: 1.4054\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0933 - val_loss: 1.4082\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0925 - val_loss: 1.4187\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0777 - val_loss: 1.3979\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0645 - val_loss: 1.3864\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0571 - val_loss: 1.3756\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0482 - val_loss: 1.3754\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0449 - val_loss: 1.3618\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0334 - val_loss: 1.3559\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.0353 - val_loss: 1.3684\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.0192 - val_loss: 1.3666\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0193 - val_loss: 1.3484\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.0048 - val_loss: 1.3457\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9990 - val_loss: 1.3407\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9929 - val_loss: 1.3347\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9883 - val_loss: 1.3278\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9873 - val_loss: 1.3174\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9782 - val_loss: 1.3229\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9707 - val_loss: 1.3234\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.9646 - val_loss: 1.3219\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9610 - val_loss: 1.3237\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9575 - val_loss: 1.3130\n",
            "[CV]  n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725, total=   5.6s\n",
            "[CV] n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 68.9000 - val_loss: 41.2216\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 40.9724 - val_loss: 25.6192\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 25.0515 - val_loss: 16.4446\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 16.0339 - val_loss: 11.3437\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 10.8763 - val_loss: 8.0079\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 7.7166 - val_loss: 6.0287\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.9015 - val_loss: 4.8797\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.8997 - val_loss: 4.1421\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 4.2740 - val_loss: 3.7901\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.9796 - val_loss: 3.5605\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.8202 - val_loss: 3.4418\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.6433 - val_loss: 3.2638\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.4988 - val_loss: 3.1671\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.3996 - val_loss: 3.0885\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3003 - val_loss: 3.0140\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 3.2145 - val_loss: 2.9218\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 3.1168 - val_loss: 2.8549\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.0335 - val_loss: 2.8082\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.9580 - val_loss: 2.7590\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.9053 - val_loss: 2.6799\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.8153 - val_loss: 2.6313\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.7429 - val_loss: 2.5965\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.6798 - val_loss: 2.5650\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.6203 - val_loss: 2.5365\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.5645 - val_loss: 2.4812\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4963 - val_loss: 2.4538\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4436 - val_loss: 2.4353\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.3829 - val_loss: 2.3904\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.3251 - val_loss: 2.3530\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.2725 - val_loss: 2.3283\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.2246 - val_loss: 2.2862\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.1808 - val_loss: 2.2762\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.1290 - val_loss: 2.2544\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.0798 - val_loss: 2.2214\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.0741 - val_loss: 2.2278\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.0024 - val_loss: 2.2004\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.9552 - val_loss: 2.1624\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.9202 - val_loss: 2.1376\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8737 - val_loss: 2.1087\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.8358 - val_loss: 2.0826\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8044 - val_loss: 2.0636\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7656 - val_loss: 2.0394\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.7347 - val_loss: 2.0083\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6949 - val_loss: 1.9893\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.6635 - val_loss: 1.9784\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.6472 - val_loss: 1.9782\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.6021 - val_loss: 1.9508\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.5739 - val_loss: 1.9343\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.5618 - val_loss: 1.8920\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.5169 - val_loss: 1.8710\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.4870 - val_loss: 1.8611\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4699 - val_loss: 1.8613\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.4411 - val_loss: 1.8340\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.4133 - val_loss: 1.8198\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.3946 - val_loss: 1.8140\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.3694 - val_loss: 1.7976\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3514 - val_loss: 1.7819\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.3288 - val_loss: 1.7676\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3099 - val_loss: 1.7608\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2901 - val_loss: 1.7473\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2709 - val_loss: 1.7371\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.2545 - val_loss: 1.7202\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.2333 - val_loss: 1.7083\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2168 - val_loss: 1.6937\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1987 - val_loss: 1.6824\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1815 - val_loss: 1.6747\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1651 - val_loss: 1.6676\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1507 - val_loss: 1.6535\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1349 - val_loss: 1.6409\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.1238 - val_loss: 1.6412\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1039 - val_loss: 1.6260\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0879 - val_loss: 1.6180\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.0734 - val_loss: 1.6104\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.0593 - val_loss: 1.6015\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0465 - val_loss: 1.5980\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.0358 - val_loss: 1.5863\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.0263 - val_loss: 1.5728\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0115 - val_loss: 1.5690\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0022 - val_loss: 1.5716\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9956 - val_loss: 1.5764\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.9830 - val_loss: 1.5756\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9693 - val_loss: 1.5595\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9584 - val_loss: 1.5460\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9475 - val_loss: 1.5404\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9380 - val_loss: 1.5357\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9322 - val_loss: 1.5203\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9243 - val_loss: 1.5061\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9103 - val_loss: 1.5040\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9036 - val_loss: 1.5074\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8993 - val_loss: 1.4938\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8874 - val_loss: 1.4860\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8811 - val_loss: 1.4905\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8694 - val_loss: 1.4862\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8662 - val_loss: 1.4739\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8563 - val_loss: 1.4684\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8495 - val_loss: 1.4635\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8425 - val_loss: 1.4629\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.8366 - val_loss: 1.4593\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8309 - val_loss: 1.4605\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8240 - val_loss: 1.4557\n",
            "[CV]  n_neurons=6, n_hidden=0, learning_rate=0.0052787610094815725, total=   4.5s\n",
            "[CV] n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 176ms/step - loss: 122.4602 - val_loss: 69.1329\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 64.1179 - val_loss: 15.3009\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 9.2189 - val_loss: 6.8663\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.1401 - val_loss: 4.4712\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 3.2540 - val_loss: 3.7091\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.9167 - val_loss: 5.0291\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.3486 - val_loss: 5.1459\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.3350 - val_loss: 5.1216\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.2074 - val_loss: 3.9437\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.9177 - val_loss: 11.9862\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 6.9840 - val_loss: 2.3801\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.5079 - val_loss: 2.2807\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.2909 - val_loss: 1.5870\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.1786 - val_loss: 2.2783\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3007 - val_loss: 1.9906\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.4479 - val_loss: 1.3919\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4756 - val_loss: 1.4799\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.1904 - val_loss: 1.3983\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.8724 - val_loss: 1.3456\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9784 - val_loss: 1.5245\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.3761 - val_loss: 1.2326\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7855 - val_loss: 2.1027\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.6496 - val_loss: 3.0793\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4228 - val_loss: 3.4008\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9948 - val_loss: 1.5366\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7582 - val_loss: 1.1951\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7009 - val_loss: 1.5235\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8037 - val_loss: 1.2115\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6932 - val_loss: 1.3089\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9071 - val_loss: 2.1519\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.4117 - val_loss: 1.7044\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0068 - val_loss: 1.3707\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0937 - val_loss: 2.6070\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.6029 - val_loss: 1.5028\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9127 - val_loss: 1.3738\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7900 - val_loss: 1.2976\n",
            "[CV]  n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017, total=   2.2s\n",
            "[CV] n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 174ms/step - loss: 99.6420 - val_loss: 58.7768\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 57.3554 - val_loss: 7.6832\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 6.9976 - val_loss: 4.4487\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.6097 - val_loss: 5.6200\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.2912 - val_loss: 3.0041\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.6319 - val_loss: 3.1909\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.1851 - val_loss: 2.3588\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.6436 - val_loss: 3.4357\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2599 - val_loss: 1.8705\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3145 - val_loss: 2.1596\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.6050 - val_loss: 1.8831\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3782 - val_loss: 1.8434\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.1344 - val_loss: 1.3187\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9028 - val_loss: 1.2455\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8514 - val_loss: 1.2275\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8116 - val_loss: 1.2103\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7830 - val_loss: 1.1608\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.8149 - val_loss: 1.6220\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0910 - val_loss: 1.4699\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7432 - val_loss: 1.3816\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0326 - val_loss: 1.0757\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7041 - val_loss: 1.1593\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7595 - val_loss: 1.3193\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8977 - val_loss: 1.4788\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8100 - val_loss: 1.0736\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7641 - val_loss: 1.2454\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9444 - val_loss: 1.0589\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6845 - val_loss: 1.3328\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0185 - val_loss: 1.9490\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5539 - val_loss: 2.1140\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.3482 - val_loss: 1.2797\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9076 - val_loss: 1.5780\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.2529 - val_loss: 2.1111\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1999 - val_loss: 1.0270\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.6349 - val_loss: 1.0580\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6428 - val_loss: 1.0880\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.6741 - val_loss: 1.1300\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7917 - val_loss: 1.5364\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9069 - val_loss: 1.0431\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6163 - val_loss: 1.0687\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9121 - val_loss: 1.0707\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7798 - val_loss: 0.9954\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6320 - val_loss: 0.9777\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6192 - val_loss: 1.0010\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6061 - val_loss: 1.0526\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7292 - val_loss: 1.3744\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7898 - val_loss: 1.0041\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6076 - val_loss: 1.0333\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5869 - val_loss: 1.1304\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7857 - val_loss: 0.9400\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5694 - val_loss: 0.9792\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6392 - val_loss: 1.2192\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6039 - val_loss: 1.0281\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6901 - val_loss: 0.9386\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6268 - val_loss: 0.9641\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5937 - val_loss: 0.9300\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5512 - val_loss: 0.9223\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5906 - val_loss: 0.9865\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6055 - val_loss: 0.9100\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5418 - val_loss: 0.9086\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5383 - val_loss: 1.0228\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5957 - val_loss: 0.9406\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5307 - val_loss: 0.9129\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6172 - val_loss: 1.0182\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8738 - val_loss: 1.0866\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7477 - val_loss: 0.9228\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6851 - val_loss: 1.0275\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.6923 - val_loss: 0.8975\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.5543 - val_loss: 0.8794\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5138 - val_loss: 0.8942\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5210 - val_loss: 1.0109\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6207 - val_loss: 0.8455\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.4991 - val_loss: 0.8838\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4978 - val_loss: 0.9056\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6637 - val_loss: 0.8980\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6841 - val_loss: 0.9666\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7019 - val_loss: 0.9113\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6266 - val_loss: 0.9170\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6150 - val_loss: 0.8496\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4849 - val_loss: 0.8740\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6995 - val_loss: 1.6923\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0483 - val_loss: 0.8783\n",
            "[CV]  n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017, total=   5.7s\n",
            "[CV] n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017 ....\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 177ms/step - loss: 77.8782 - val_loss: 27.4845\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 21.3711 - val_loss: 8.2925\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 7.0177 - val_loss: 10.9668\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.7497 - val_loss: 7.6708\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.7736 - val_loss: 5.3646\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.3845 - val_loss: 5.7918\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 7.2730 - val_loss: 6.4486\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 9.8589 - val_loss: 5.2386\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.9351 - val_loss: 3.4975\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.8539 - val_loss: 3.2375\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.8419 - val_loss: 3.0023\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.5487 - val_loss: 2.8443\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.3743 - val_loss: 2.5333\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3163 - val_loss: 2.4102\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1642 - val_loss: 2.5912\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.1466 - val_loss: 2.4009\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1419 - val_loss: 2.9038\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.5082 - val_loss: 2.9760\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2572 - val_loss: 2.0543\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9536 - val_loss: 2.4212\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.2775 - val_loss: 1.8957\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8388 - val_loss: 1.8698\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7802 - val_loss: 1.8822\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7032 - val_loss: 1.7730\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8013 - val_loss: 1.7581\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8908 - val_loss: 1.7120\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7058 - val_loss: 1.7440\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.6556 - val_loss: 1.6598\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6611 - val_loss: 1.6358\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6339 - val_loss: 1.7090\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6351 - val_loss: 1.6681\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.7397 - val_loss: 2.5448\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.4368 - val_loss: 3.0505\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.7414 - val_loss: 2.5644\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.9096 - val_loss: 4.1393\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.8090 - val_loss: 3.0919\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.9738 - val_loss: 2.8931\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.1868 - val_loss: 1.5828\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5884 - val_loss: 1.5415\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.5974 - val_loss: 1.5189\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7564 - val_loss: 1.4798\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5767 - val_loss: 1.8855\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8164 - val_loss: 1.8859\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8430 - val_loss: 1.9465\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9806 - val_loss: 2.1825\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2942 - val_loss: 2.7159\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.3534 - val_loss: 1.9501\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.7628 - val_loss: 1.5061\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5628 - val_loss: 1.4460\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5486 - val_loss: 1.4060\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.5534 - val_loss: 1.3902\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5686 - val_loss: 1.8231\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7964 - val_loss: 1.6583\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7160 - val_loss: 1.6930\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7149 - val_loss: 1.5572\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7006 - val_loss: 1.9160\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7378 - val_loss: 1.4338\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5538 - val_loss: 1.4623\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6096 - val_loss: 1.6593\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6465 - val_loss: 1.4261\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5231 - val_loss: 1.3168\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5300 - val_loss: 1.3239\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5227 - val_loss: 1.2963\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5171 - val_loss: 1.5258\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5160 - val_loss: 1.3331\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7970 - val_loss: 1.3480\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8156 - val_loss: 1.2792\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6990 - val_loss: 1.3004\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7647 - val_loss: 1.3053\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5722 - val_loss: 1.3378\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5214 - val_loss: 1.3980\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8408 - val_loss: 1.2242\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.6862 - val_loss: 1.3010\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9983 - val_loss: 1.4928\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.8962 - val_loss: 1.2426\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5386 - val_loss: 1.2336\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6074 - val_loss: 1.2942\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5879 - val_loss: 1.2330\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5246 - val_loss: 1.7186\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0488 - val_loss: 2.2834\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3141 - val_loss: 1.8922\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9422 - val_loss: 1.5174\n",
            "[CV]  n_neurons=12, n_hidden=2, learning_rate=0.006031940806368017, total=   3.9s\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 180ms/step - loss: 105.3065 - val_loss: 90.7966\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 102.6429 - val_loss: 88.6694\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 100.3209 - val_loss: 86.7017\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 98.1493 - val_loss: 84.7533\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 95.9440 - val_loss: 82.7547\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 93.6515 - val_loss: 80.6200\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 91.1214 - val_loss: 78.1938\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 88.1266 - val_loss: 75.3699\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 84.5651 - val_loss: 72.2315\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 80.4334 - val_loss: 68.2532\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 75.3769 - val_loss: 63.4855\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 69.4268 - val_loss: 57.6851\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 62.2032 - val_loss: 50.7358\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 53.6302 - val_loss: 42.5864\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 43.8251 - val_loss: 33.7481\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 33.5969 - val_loss: 25.2406\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 24.0249 - val_loss: 17.7854\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 16.1699 - val_loss: 12.2231\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 10.9213 - val_loss: 8.9268\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.2062 - val_loss: 7.0711\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 6.9761 - val_loss: 6.4126\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.7192 - val_loss: 6.2977\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.4467 - val_loss: 6.0134\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.2153 - val_loss: 5.7309\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 6.0613 - val_loss: 5.6383\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 5.9823 - val_loss: 5.2837\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 5.7399 - val_loss: 5.2253\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.6171 - val_loss: 5.0767\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 5.4776 - val_loss: 4.9681\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.3537 - val_loss: 4.9369\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.2329 - val_loss: 4.8929\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.1182 - val_loss: 4.8127\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 5.1250 - val_loss: 4.9264\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.9321 - val_loss: 4.7319\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.8154 - val_loss: 4.6084\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 4.7138 - val_loss: 4.4943\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.7723 - val_loss: 4.2595\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 4.6092 - val_loss: 4.4052\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.4423 - val_loss: 4.2797\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.4191 - val_loss: 4.0964\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.2755 - val_loss: 4.0679\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.2388 - val_loss: 4.1769\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 4.1027 - val_loss: 4.0373\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.0199 - val_loss: 3.9399\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.9726 - val_loss: 3.8144\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.8903 - val_loss: 3.8718\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.8130 - val_loss: 3.8742\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.7819 - val_loss: 3.8970\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.6896 - val_loss: 3.8127\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.6141 - val_loss: 3.7446\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.5575 - val_loss: 3.7153\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.4720 - val_loss: 3.5512\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.4089 - val_loss: 3.4369\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.3878 - val_loss: 3.3241\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.3056 - val_loss: 3.2903\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 3.2758 - val_loss: 3.2229\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.2426 - val_loss: 3.3578\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.1138 - val_loss: 3.3129\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.0722 - val_loss: 3.2984\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0070 - val_loss: 3.1979\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.9575 - val_loss: 3.1038\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.9021 - val_loss: 3.0988\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.8750 - val_loss: 2.9828\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.8021 - val_loss: 2.9691\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.7507 - val_loss: 2.9426\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.7155 - val_loss: 2.9742\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6831 - val_loss: 2.8504\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.6508 - val_loss: 2.9272\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.6225 - val_loss: 2.9578\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.5474 - val_loss: 2.8777\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.5030 - val_loss: 2.8357\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.4515 - val_loss: 2.7381\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.4111 - val_loss: 2.6643\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3677 - val_loss: 2.6311\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.3356 - val_loss: 2.5831\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.2983 - val_loss: 2.5510\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 2.2905 - val_loss: 2.6224\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2260 - val_loss: 2.5820\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2050 - val_loss: 2.4759\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.1687 - val_loss: 2.4231\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1256 - val_loss: 2.4409\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 2.1566 - val_loss: 2.3375\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.0717 - val_loss: 2.3756\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.0289 - val_loss: 2.3468\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.0024 - val_loss: 2.3657\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9743 - val_loss: 2.3629\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.9407 - val_loss: 2.3056\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.9654 - val_loss: 2.3826\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8970 - val_loss: 2.3072\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.9241 - val_loss: 2.1651\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8389 - val_loss: 2.2022\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8093 - val_loss: 2.1478\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7780 - val_loss: 2.1247\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.7580 - val_loss: 2.0880\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.7315 - val_loss: 2.0674\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7035 - val_loss: 2.0933\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.6726 - val_loss: 2.0678\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.6550 - val_loss: 2.0837\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.6275 - val_loss: 2.0632\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6057 - val_loss: 2.0026\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097, total=   4.3s\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 183ms/step - loss: 99.4665 - val_loss: 81.9646\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 92.6334 - val_loss: 75.0869\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 84.4405 - val_loss: 67.1213\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 74.8458 - val_loss: 57.6357\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 63.2529 - val_loss: 46.2270\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 49.7210 - val_loss: 34.1943\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 35.5758 - val_loss: 22.3705\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 22.3539 - val_loss: 12.9787\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12.8961 - val_loss: 8.4457\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 8.4800 - val_loss: 6.5420\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 6.5176 - val_loss: 5.5885\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.6117 - val_loss: 5.1127\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 5.1734 - val_loss: 4.7924\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.8587 - val_loss: 4.5903\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.6179 - val_loss: 4.4288\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.3916 - val_loss: 4.2647\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.1953 - val_loss: 4.1171\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.0481 - val_loss: 4.0211\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.8363 - val_loss: 3.8754\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.8928 - val_loss: 3.6789\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 3.5260 - val_loss: 3.5753\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.3496 - val_loss: 3.5079\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.2269 - val_loss: 3.4350\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.0864 - val_loss: 3.3226\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.9671 - val_loss: 3.2097\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.8846 - val_loss: 3.0985\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7714 - val_loss: 3.0666\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6348 - val_loss: 2.9703\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.5432 - val_loss: 2.8745\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.4599 - val_loss: 2.8394\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.3767 - val_loss: 2.7628\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.3098 - val_loss: 2.7374\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.2622 - val_loss: 2.7162\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.1824 - val_loss: 2.6534\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 2.1066 - val_loss: 2.5900\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.0374 - val_loss: 2.5326\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.9800 - val_loss: 2.4456\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.9199 - val_loss: 2.4324\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.8567 - val_loss: 2.3681\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.8098 - val_loss: 2.3072\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7546 - val_loss: 2.2731\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7230 - val_loss: 2.2806\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.6664 - val_loss: 2.2226\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.6220 - val_loss: 2.1719\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.5913 - val_loss: 2.1765\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.5618 - val_loss: 2.1627\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5157 - val_loss: 2.1000\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.4936 - val_loss: 2.1029\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.4840 - val_loss: 2.0120\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.4245 - val_loss: 2.0088\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.3888 - val_loss: 1.9875\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.3720 - val_loss: 1.9965\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3601 - val_loss: 1.9176\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3170 - val_loss: 1.9061\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2971 - val_loss: 1.8861\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.2838 - val_loss: 1.8609\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2608 - val_loss: 1.8750\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2372 - val_loss: 1.8429\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.2216 - val_loss: 1.8480\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.2051 - val_loss: 1.8091\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1887 - val_loss: 1.8142\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1708 - val_loss: 1.7941\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.1715 - val_loss: 1.7468\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1578 - val_loss: 1.7288\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1509 - val_loss: 1.7102\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1215 - val_loss: 1.7286\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.1061 - val_loss: 1.7031\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.0959 - val_loss: 1.7227\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.0837 - val_loss: 1.7193\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.0789 - val_loss: 1.7184\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0669 - val_loss: 1.6600\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.0474 - val_loss: 1.6542\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.0381 - val_loss: 1.6454\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.0327 - val_loss: 1.6224\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.0238 - val_loss: 1.6143\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0133 - val_loss: 1.6118\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.0058 - val_loss: 1.6069\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9999 - val_loss: 1.5936\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9974 - val_loss: 1.5781\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9890 - val_loss: 1.5907\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0209 - val_loss: 1.6467\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9898 - val_loss: 1.5761\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9680 - val_loss: 1.5659\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9645 - val_loss: 1.5503\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9588 - val_loss: 1.5588\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9648 - val_loss: 1.5258\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9555 - val_loss: 1.5196\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9735 - val_loss: 1.5767\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.9459 - val_loss: 1.5521\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.9476 - val_loss: 1.5031\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.9290 - val_loss: 1.5066\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9293 - val_loss: 1.4916\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9208 - val_loss: 1.4930\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9161 - val_loss: 1.4863\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9232 - val_loss: 1.4679\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.9164 - val_loss: 1.4982\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9054 - val_loss: 1.4937\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9011 - val_loss: 1.4894\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.8959 - val_loss: 1.4800\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9017 - val_loss: 1.4455\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097, total=   5.7s\n",
            "[CV] n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 171ms/step - loss: 96.6004 - val_loss: 78.7030\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 83.4888 - val_loss: 67.5512\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 70.9735 - val_loss: 55.1765\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 57.2056 - val_loss: 41.4479\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 41.7044 - val_loss: 27.3147\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 26.4095 - val_loss: 16.1973\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14.8236 - val_loss: 9.4262\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.1713 - val_loss: 6.3993\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 5.4194 - val_loss: 5.4757\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.6393 - val_loss: 5.1695\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 4.4496 - val_loss: 5.0550\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.2355 - val_loss: 4.8558\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.0653 - val_loss: 4.7167\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.9369 - val_loss: 4.6071\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 3.8074 - val_loss: 4.4952\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.7289 - val_loss: 4.3623\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 3.5792 - val_loss: 4.2674\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4743 - val_loss: 4.1973\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.3606 - val_loss: 4.0994\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.2846 - val_loss: 3.9787\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.1679 - val_loss: 3.8988\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 3.0736 - val_loss: 3.8250\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.9854 - val_loss: 3.7532\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.9089 - val_loss: 3.6942\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.8702 - val_loss: 3.5869\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.7550 - val_loss: 3.5380\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 2.6783 - val_loss: 3.4966\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.6163 - val_loss: 3.3988\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.5304 - val_loss: 3.3351\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4633 - val_loss: 3.2721\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 2.4154 - val_loss: 3.2047\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.3548 - val_loss: 3.1927\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.3099 - val_loss: 3.1751\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.2307 - val_loss: 3.1041\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.2640 - val_loss: 3.1320\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 2.1634 - val_loss: 3.0580\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.0790 - val_loss: 2.9675\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.0150 - val_loss: 2.9016\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.9571 - val_loss: 2.8541\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.9166 - val_loss: 2.8244\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8775 - val_loss: 2.7914\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.8411 - val_loss: 2.7689\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.7935 - val_loss: 2.6846\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.7377 - val_loss: 2.6606\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7050 - val_loss: 2.6464\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.6884 - val_loss: 2.6410\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.6310 - val_loss: 2.5682\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.5927 - val_loss: 2.5479\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.5875 - val_loss: 2.4718\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5300 - val_loss: 2.4422\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4882 - val_loss: 2.4319\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.4865 - val_loss: 2.4536\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.4283 - val_loss: 2.3968\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.3945 - val_loss: 2.3631\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.3774 - val_loss: 2.3573\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3408 - val_loss: 2.3131\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.3163 - val_loss: 2.2807\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2889 - val_loss: 2.2624\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.2663 - val_loss: 2.2507\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.2425 - val_loss: 2.2161\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.2181 - val_loss: 2.1917\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2004 - val_loss: 2.1603\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1765 - val_loss: 2.1409\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.1553 - val_loss: 2.1201\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.1314 - val_loss: 2.1059\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.1092 - val_loss: 2.0949\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.0893 - val_loss: 2.0840\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.0724 - val_loss: 2.0503\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0529 - val_loss: 2.0281\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.0456 - val_loss: 2.0401\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.0230 - val_loss: 1.9914\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9959 - val_loss: 1.9816\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.9786 - val_loss: 1.9606\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9612 - val_loss: 1.9497\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.9555 - val_loss: 1.9593\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9338 - val_loss: 1.9373\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9229 - val_loss: 1.9052\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.9077 - val_loss: 1.9038\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8977 - val_loss: 1.9089\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8955 - val_loss: 1.9149\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8930 - val_loss: 1.9158\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8643 - val_loss: 1.8742\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8471 - val_loss: 1.8394\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.8334 - val_loss: 1.8341\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.8237 - val_loss: 1.8295\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8288 - val_loss: 1.7868\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8186 - val_loss: 1.7680\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7971 - val_loss: 1.7694\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7890 - val_loss: 1.7875\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.7846 - val_loss: 1.7537\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7774 - val_loss: 1.7367\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7632 - val_loss: 1.7524\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7491 - val_loss: 1.7428\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7443 - val_loss: 1.7226\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7339 - val_loss: 1.7193\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7300 - val_loss: 1.7037\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7207 - val_loss: 1.7086\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.7142 - val_loss: 1.7010\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7087 - val_loss: 1.7031\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.7041 - val_loss: 1.6820\n",
            "[CV]  n_neurons=10, n_hidden=2, learning_rate=0.0010800232940482097, total=   4.6s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 85ms/step - loss: 87.4121 - val_loss: 15.2043\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 9.3596 - val_loss: 3.2653\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.2116 - val_loss: 2.2133\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.5028 - val_loss: 2.1957\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 1.3583 - val_loss: 1.8631\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.6302 - val_loss: 1.7709\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.0303 - val_loss: 1.7990\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.2147 - val_loss: 1.5064\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8769 - val_loss: 1.6115\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8624 - val_loss: 1.2676\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8619 - val_loss: 1.2139\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7425 - val_loss: 1.2608\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.1818 - val_loss: 1.2452\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9645 - val_loss: 1.4263\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.8761 - val_loss: 1.3607\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.9504 - val_loss: 1.1565\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.7545 - val_loss: 1.4904\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.7116 - val_loss: 1.1049\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7381 - val_loss: 1.1980\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.3152 - val_loss: 1.1745\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6951 - val_loss: 1.1648\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7105 - val_loss: 1.1149\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6725 - val_loss: 1.1080\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6518 - val_loss: 1.1102\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6659 - val_loss: 1.1309\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7029 - val_loss: 1.1293\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6432 - val_loss: 1.1040\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6689 - val_loss: 1.1689\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6692 - val_loss: 1.1522\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6289 - val_loss: 1.2915\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7531 - val_loss: 1.6502\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.3178 - val_loss: 1.1175\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7079 - val_loss: 1.1047\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6431 - val_loss: 1.0771\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6967 - val_loss: 1.2161\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.8014 - val_loss: 1.0723\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6072 - val_loss: 1.1234\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6165 - val_loss: 1.0859\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6956 - val_loss: 1.1813\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6365 - val_loss: 1.4362\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6791 - val_loss: 1.0770\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.5854 - val_loss: 1.0810\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5931 - val_loss: 1.1169\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5930 - val_loss: 1.1448\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5955 - val_loss: 1.0667\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5989 - val_loss: 1.0401\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6450 - val_loss: 1.0255\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5623 - val_loss: 1.0574\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6453 - val_loss: 1.0843\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.8577 - val_loss: 1.0127\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5821 - val_loss: 1.1284\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6629 - val_loss: 1.0426\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5827 - val_loss: 1.0608\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5654 - val_loss: 0.9866\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7273 - val_loss: 1.1574\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5922 - val_loss: 1.1859\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5903 - val_loss: 1.0133\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5294 - val_loss: 0.9792\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.5306 - val_loss: 0.9695\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6195 - val_loss: 1.0323\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5327 - val_loss: 1.0062\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5780 - val_loss: 1.0417\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5197 - val_loss: 0.9968\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5309 - val_loss: 1.1706\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5680 - val_loss: 0.9637\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5125 - val_loss: 0.9834\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5204 - val_loss: 0.9853\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5975 - val_loss: 0.9781\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5707 - val_loss: 0.9956\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5049 - val_loss: 1.0009\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5053 - val_loss: 0.9841\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6085 - val_loss: 0.9273\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5139 - val_loss: 1.0455\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5444 - val_loss: 0.9773\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.7245 - val_loss: 0.9355\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5304 - val_loss: 0.9337\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4909 - val_loss: 0.9177\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4889 - val_loss: 1.0336\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.5140 - val_loss: 1.0476\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4938 - val_loss: 0.9084\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4823 - val_loss: 1.0763\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5330 - val_loss: 0.9420\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4853 - val_loss: 0.9342\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5095 - val_loss: 0.9308\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4686 - val_loss: 1.3344\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.8755 - val_loss: 1.0120\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6301 - val_loss: 0.9853\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4910 - val_loss: 1.0631\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7215 - val_loss: 0.9028\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.4727 - val_loss: 1.1134\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5672 - val_loss: 1.4802\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.5882 - val_loss: 0.8990\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.4986 - val_loss: 0.8883\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4798 - val_loss: 0.9360\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.5994 - val_loss: 0.9405\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4768 - val_loss: 0.8913\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.5635 - val_loss: 1.2333\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8194 - val_loss: 1.0426\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6694 - val_loss: 0.8852\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.4544 - val_loss: 0.8765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f05dbaa1490>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': [0.0008338877555681813,\n",
              "                                                          0.016541918130355184,\n",
              "                                                          0.0007772479144538126,\n",
              "                                                          0.020622583494082258,\n",
              "                                                          0.0028440919448039343,\n",
              "                                                          0.005018905061000662,\n",
              "                                                          0.010207913180806806,\n",
              "                                                          0.0032...\n",
              "                                                          0.0011129944943165159,\n",
              "                                                          0.0009644898603208138,\n",
              "                                                          0.0013559670930680175,\n",
              "                                                          0.0005827064911743814,\n",
              "                                                          0.0006432013942093604,\n",
              "                                                          0.025408692236078737,\n",
              "                                                          0.024978979138210063,\n",
              "                                                          0.0007144150023057141, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='neg_mean_absolute_error',\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKTbYrmZHD8A",
        "outputId": "17316289-e33f-4f91-f059-cd8a2c7e6607"
      },
      "source": [
        "rnd_search_cv.best_params_\n",
        "#데이터의 인공신경망 모델은 은닉층의 개수는 1개, 뉴런개수는 13개가 최적화된 모델이라고 할 수 있다. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.011535688495495584, 'n_hidden': 1, 'n_neurons': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDhwtIUBPIuQ",
        "outputId": "d22f4f34-83b7-4e67-acc1-23e225c34797"
      },
      "source": [
        "#신경망 만들고 데이터 적용시켜보기\n",
        "tf.random.set_seed(5)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "layer=keras.layers.Dense(4, activation='relu',kernel_initializer='he_normal')\n",
        "model=keras.Sequential([keras.layers.Dense(13, activation='selu', kernel_initializer='lecun_normal'),\n",
        "                        keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "model.compile(optimizer='SGD', loss='mean_squared_error',loss_weights=[0.9,0.1],metrics='mae')\n",
        "history=model.fit(x_train,y_train,epochs=50, batch_size=10, validation_data=(x_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 15.1091 - mae: 2.3968 - val_loss: 1.4962 - val_mae: 1.0075\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8875 - mae: 0.8331 - val_loss: 1.0388 - val_mae: 0.8427\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7660 - mae: 0.7845 - val_loss: 1.0727 - val_mae: 0.9064\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5771 - mae: 0.6593 - val_loss: 0.7719 - val_mae: 0.7428\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4539 - mae: 0.5930 - val_loss: 0.7122 - val_mae: 0.7261\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4276 - mae: 0.5724 - val_loss: 0.6640 - val_mae: 0.7099\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3855 - mae: 0.5347 - val_loss: 0.6152 - val_mae: 0.6197\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3625 - mae: 0.5142 - val_loss: 0.6736 - val_mae: 0.7522\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3703 - mae: 0.5423 - val_loss: 0.5467 - val_mae: 0.6343\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3660 - mae: 0.5234 - val_loss: 0.5128 - val_mae: 0.5876\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3503 - mae: 0.5043 - val_loss: 0.5258 - val_mae: 0.6421\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3191 - mae: 0.4851 - val_loss: 1.1294 - val_mae: 1.0136\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4502 - mae: 0.5885 - val_loss: 0.5471 - val_mae: 0.5654\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3635 - mae: 0.5292 - val_loss: 0.4917 - val_mae: 0.6446\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2887 - mae: 0.4924 - val_loss: 0.7734 - val_mae: 0.6569\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3712 - mae: 0.5128 - val_loss: 0.4573 - val_mae: 0.6231\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3098 - mae: 0.4650 - val_loss: 0.4295 - val_mae: 0.5849\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2933 - mae: 0.4660 - val_loss: 0.4134 - val_mae: 0.5571\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2716 - mae: 0.4394 - val_loss: 0.4064 - val_mae: 0.5514\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3189 - mae: 0.4991 - val_loss: 0.4074 - val_mae: 0.5625\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2594 - mae: 0.4270 - val_loss: 0.4940 - val_mae: 0.6640\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2935 - mae: 0.4834 - val_loss: 0.4553 - val_mae: 0.4865\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2915 - mae: 0.4529 - val_loss: 0.4282 - val_mae: 0.4772\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2541 - mae: 0.4332 - val_loss: 0.4594 - val_mae: 0.4807\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3025 - mae: 0.4717 - val_loss: 0.4842 - val_mae: 0.4945\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2625 - mae: 0.4216 - val_loss: 0.3650 - val_mae: 0.5099\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2720 - mae: 0.4544 - val_loss: 0.3876 - val_mae: 0.4588\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2731 - mae: 0.4558 - val_loss: 0.4625 - val_mae: 0.4823\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2861 - mae: 0.4619 - val_loss: 0.3509 - val_mae: 0.4832\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2281 - mae: 0.4077 - val_loss: 0.3282 - val_mae: 0.4988\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2547 - mae: 0.4411 - val_loss: 0.3205 - val_mae: 0.4744\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2589 - mae: 0.4215 - val_loss: 0.3321 - val_mae: 0.5351\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2274 - mae: 0.4244 - val_loss: 0.3732 - val_mae: 0.4381\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2172 - mae: 0.3838 - val_loss: 0.3692 - val_mae: 0.5868\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2229 - mae: 0.4091 - val_loss: 0.3309 - val_mae: 0.4377\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2256 - mae: 0.3885 - val_loss: 0.3180 - val_mae: 0.4498\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2127 - mae: 0.3762 - val_loss: 0.3025 - val_mae: 0.5143\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2152 - mae: 0.4033 - val_loss: 0.3024 - val_mae: 0.5002\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1988 - mae: 0.3916 - val_loss: 0.2949 - val_mae: 0.4976\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2050 - mae: 0.3925 - val_loss: 0.3055 - val_mae: 0.4023\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1973 - mae: 0.3764 - val_loss: 0.3156 - val_mae: 0.5463\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2020 - mae: 0.3844 - val_loss: 0.3178 - val_mae: 0.5488\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2162 - mae: 0.4029 - val_loss: 0.2839 - val_mae: 0.5017\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1972 - mae: 0.3832 - val_loss: 0.3533 - val_mae: 0.4189\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1889 - mae: 0.3578 - val_loss: 0.2534 - val_mae: 0.4676\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1749 - mae: 0.3544 - val_loss: 0.2817 - val_mae: 0.3817\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1821 - mae: 0.3708 - val_loss: 0.2776 - val_mae: 0.3707\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1871 - mae: 0.3627 - val_loss: 0.2360 - val_mae: 0.3950\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1735 - mae: 0.3677 - val_loss: 0.2254 - val_mae: 0.4243\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1816 - mae: 0.3666 - val_loss: 0.2660 - val_mae: 0.3650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYnx_tlRmQJ_",
        "outputId": "6d0ecaf1-d574-4fe1-ad1f-2579b63b0c6a"
      },
      "source": [
        "#결과\n",
        "val_mse, val_mae=model.evaluate(x_test, y_test)\n",
        "val_mse, val_mae=model.evaluate(test, test_y_noise)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2660 - mae: 0.3650\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4872 - mae: 0.5647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "jQOKH6iReEq-",
        "outputId": "e0aac3fc-8fd5-411f-e5e1-acd30f7ceef1"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.xlabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "MMcVvEoJkH69",
        "outputId": "5500d388-0d03-4d87-c8b9-c701e904508b"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is4b9eYulkO4",
        "outputId": "1cf0cc03-e3f0-4f14-c04f-d94d756fd2a6"
      },
      "source": [
        "#Mexican 활성화 함수 추가한 결과\n",
        "tf.random.set_seed(5)\n",
        "layer=keras.layers.Dense(4, activation='relu',kernel_initializer='he_normal')\n",
        "model=keras.Sequential([keras.layers.Dense(13, activation=mexican),\n",
        "                        keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "opt=keras.optimizers.Adam(learning_rate=0.005)\n",
        "model.compile(optimizer='SGD', loss='mean_squared_error',loss_weights=[0.9,0.1],metrics='mae')\n",
        "history=model.fit(x_train,y_train,epochs=50, batch_size=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 54.5917 - mae: 7.4583 - val_loss: 31.8415 - val_mae: 5.7645\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 28.7267 - mae: 5.2572 - val_loss: 11.8079 - val_mae: 3.4077\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3489 - mae: 2.2907 - val_loss: 2.0713 - val_mae: 1.2606\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3858 - mae: 1.3453 - val_loss: 0.9884 - val_mae: 0.8377\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4686 - mae: 1.0394 - val_loss: 0.7036 - val_mae: 0.6736\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9508 - mae: 0.8271 - val_loss: 0.4491 - val_mae: 0.5865\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7129 - mae: 0.6910 - val_loss: 0.3674 - val_mae: 0.5364\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5443 - mae: 0.6021 - val_loss: 0.3718 - val_mae: 0.5547\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4633 - mae: 0.5715 - val_loss: 0.4291 - val_mae: 0.5241\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4224 - mae: 0.5342 - val_loss: 0.3526 - val_mae: 0.4792\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3548 - mae: 0.4941 - val_loss: 0.3216 - val_mae: 0.5009\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4218 - mae: 0.5555 - val_loss: 0.3141 - val_mae: 0.4906\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2872 - mae: 0.4384 - val_loss: 0.3190 - val_mae: 0.4746\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2599 - mae: 0.4209 - val_loss: 0.2710 - val_mae: 0.4582\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2413 - mae: 0.4148 - val_loss: 0.5204 - val_mae: 0.6109\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2772 - mae: 0.4447 - val_loss: 0.1926 - val_mae: 0.3655\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1949 - mae: 0.3566 - val_loss: 0.1930 - val_mae: 0.3714\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2361 - mae: 0.4241 - val_loss: 0.2474 - val_mae: 0.4478\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1786 - mae: 0.3472 - val_loss: 0.2615 - val_mae: 0.4523\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1924 - mae: 0.3779 - val_loss: 0.1611 - val_mae: 0.3543\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1490 - mae: 0.3059 - val_loss: 0.1164 - val_mae: 0.2801\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1289 - mae: 0.2856 - val_loss: 0.1892 - val_mae: 0.3648\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1323 - mae: 0.2957 - val_loss: 0.1120 - val_mae: 0.2788\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1422 - mae: 0.3137 - val_loss: 0.2386 - val_mae: 0.4237\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1659 - mae: 0.3463 - val_loss: 0.5894 - val_mae: 0.6461\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1448 - mae: 0.2973 - val_loss: 0.1187 - val_mae: 0.2904\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1282 - mae: 0.3012 - val_loss: 0.0992 - val_mae: 0.2569\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1195 - mae: 0.2958 - val_loss: 0.1850 - val_mae: 0.3466\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1377 - mae: 0.2972 - val_loss: 0.0820 - val_mae: 0.2459\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0888 - mae: 0.2337 - val_loss: 0.0721 - val_mae: 0.2102\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0928 - mae: 0.2485 - val_loss: 0.0736 - val_mae: 0.2198\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0869 - mae: 0.2299 - val_loss: 0.0915 - val_mae: 0.2518\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0782 - mae: 0.2161 - val_loss: 0.1379 - val_mae: 0.3149\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0763 - mae: 0.2254 - val_loss: 0.0622 - val_mae: 0.1982\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2232 - val_loss: 0.0946 - val_mae: 0.2667\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1048 - mae: 0.2598 - val_loss: 0.0652 - val_mae: 0.2060\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - mae: 0.2208 - val_loss: 0.0884 - val_mae: 0.2519\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0727 - mae: 0.2253 - val_loss: 0.0735 - val_mae: 0.2178\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0694 - mae: 0.2108 - val_loss: 0.1069 - val_mae: 0.2622\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 0.1921 - val_loss: 0.0562 - val_mae: 0.1916\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0639 - mae: 0.2013 - val_loss: 0.0826 - val_mae: 0.2484\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0642 - mae: 0.2067 - val_loss: 0.0854 - val_mae: 0.2369\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0696 - mae: 0.2208 - val_loss: 0.0747 - val_mae: 0.2300\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - mae: 0.1923 - val_loss: 0.0552 - val_mae: 0.1939\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0717 - mae: 0.2238 - val_loss: 0.0910 - val_mae: 0.2454\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0688 - mae: 0.2245 - val_loss: 0.0986 - val_mae: 0.2446\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0542 - mae: 0.1912 - val_loss: 0.0541 - val_mae: 0.1859\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0557 - mae: 0.1915 - val_loss: 0.0547 - val_mae: 0.1855\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 0.1836 - val_loss: 0.1799 - val_mae: 0.3679\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0667 - mae: 0.2189 - val_loss: 0.0518 - val_mae: 0.1842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8q89HNxl93I",
        "outputId": "c13c9fea-0384-4bf3-fb58-c19a1f0ba830"
      },
      "source": [
        "#결과\n",
        "val_mse, val_mae=model.evaluate(x_test, y_test)\n",
        "val_mse, val_mae=model.evaluate(test, test_y_noise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0518 - mae: 0.1842\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3256 - mae: 0.4941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YPfwsaOH4HZT",
        "outputId": "95ae5bec-a427-48f3-87c9-ba75d6cd0676"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.xlabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "21fH7eZw4Lqi",
        "outputId": "0bd6f26f-0a24-4512-ef84-82634694528c"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flbj2F_WC561",
        "outputId": "87a09e62-a6c0-4a03-ce83-db21125cc694"
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "tf.random.set_seed(5)\n",
        "# 옵티마이저\n",
        "momentum=keras.optimizers.SGD(learning_rate=0.001,momentum=0.9)\n",
        "nes=keras.optimizers.SGD(learning_rate=0.001,momentum=0.9, nesterov=True)\n",
        "rmsprop=keras.optimizers.RMSprop(learning_rate=0.001,rho=0.9)\n",
        "opt=keras.optimizers.Adam(learning_rate=0.005)\n",
        "# Function to create model\n",
        "def create_model(optimizer='Adam'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(4, activation='relu', kernel_initializer='he_normal'))\n",
        "\tmodel.add(Dense(13, activation=mexican))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(5)\n",
        "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam','momentum','nes','opt']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid,n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "#이 모델에서는 adam 옵티마이저가 가장 적합하다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: -85.079002 using {'optimizer': 'Adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyc4yRnuKNtW"
      },
      "source": [
        "#mexican 활성화 함수를 추가한 결과, 손실함수와 mae가 학습데이터, 검증데이터에서 현저히 줄어들며 데이터를 더 잘 예측할 수 있게 되었다."
      ]
    }
  ]
}